{"id": 0, "prompt": "USER: What is the difference between OpenCL and CUDA?\nASSISTANT:", "timestamp": 1.59174901632622, "model": "meta-llama/Llama-2-7b-hf", "min_tokens": 256, "max_tokens": 256}
{"id": 1, "prompt": "USER: Why did my parent not invite me to their wedding?\nASSISTANT:", "timestamp": 4.103610542257895, "model": "vicuna-7b-2", "min_tokens": 256, "max_tokens": 256}
{"id": 2, "prompt": "USER: Fuji vs. Nikon, which is better?\nASSISTANT:", "timestamp": 5.950056833866033, "model": "vicuna-7b-3", "min_tokens": 256, "max_tokens": 256}
{"id": 3, "prompt": "USER: How to build an arena for chatbots?\nASSISTANT:", "timestamp": 7.524459138500575, "model": "vicuna-7b-8", "min_tokens": 256, "max_tokens": 256}
{"id": 4, "prompt": "USER: When is it today?\nASSISTANT:", "timestamp": 8.626556120691573, "model": "vicuna-7b-1", "min_tokens": 256, "max_tokens": 256}
{"id": 5, "prompt": "USER: Count from 1 to 10 with step = 3\nASSISTANT:", "timestamp": 10.702874710578792, "model": "vicuna-7b-3", "min_tokens": 256, "max_tokens": 256}
{"id": 6, "prompt": "USER: Emoji for \"sharing\". List 10\nASSISTANT:", "timestamp": 11.853913108916071, "model": "vicuna-7b-3", "min_tokens": 256, "max_tokens": 256}
{"id": 7, "prompt": "USER: How to parallelize a neural network?\nASSISTANT:", "timestamp": 16.300961934981384, "model": "vicuna-7b-3", "min_tokens": 256, "max_tokens": 256}
{"id": 8, "prompt": "USER: A = 5, B =10, A+B=?\nASSISTANT:", "timestamp": 22.93078629908901, "model": "vicuna-7b-7", "min_tokens": 256, "max_tokens": 256}
{"id": 9, "prompt": "USER: A = 5, B =10, A+B=?\nASSISTANT:", "timestamp": 23.897990500893517, "model": "meta-llama/Llama-2-7b-hf", "min_tokens": 256, "max_tokens": 256}
{"id": 10, "prompt": "USER: What is the future of bitcoin?\nASSISTANT:", "timestamp": 27.035782780831852, "model": "vicuna-7b-1", "min_tokens": 256, "max_tokens": 256}
{"id": 11, "prompt": "USER: Make it more polite: I want to have dinner.\nASSISTANT:", "timestamp": 28.54113099990503, "model": "meta-llama/Llama-2-7b-hf", "min_tokens": 256, "max_tokens": 256}
