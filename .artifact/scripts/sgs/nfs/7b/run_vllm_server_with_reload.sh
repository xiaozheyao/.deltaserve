python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-2-7b-hf --enable-delta --disable-log-requests --gpu-memory-utilization 0.85 \
--swap-modules delta-1=/mnt/scratch/xiayao/projects/fmsys/vllm/.idea/models/7b/full/vicuna-7b-v1.5-1 delta-2=/mnt/scratch/xiayao/projects/fmsys/vllm/.idea/models/7b/full/vicuna-7b-v1.5-2 delta-3=/mnt/scratch/xiayao/projects/fmsys/vllm/.idea/models/7b/full/vicuna-7b-v1.5-3 delta-4=/mnt/scratch/xiayao/projects/fmsys/vllm/.idea/models/7b/full/vicuna-7b-v1.5-4 delta-5=/mnt/scratch/xiayao/projects/fmsys/vllm/.idea/models/7b/full/vicuna-7b-v1.5-5 delta-6=/mnt/scratch/xiayao/projects/fmsys/vllm/.idea/models/7b/full/vicuna-7b-v1.5-6 delta-7=/mnt/scratch/xiayao/projects/fmsys/vllm/.idea/models/7b/full/vicuna-7b-v1.5-7 delta-8=/mnt/scratch/xiayao/projects/fmsys/vllm/.idea/models/7b/full/vicuna-7b-v1.5-8 --tensor-parallel-size 2 \
--enforce-eager --max-deltas 0