python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-2-7b-hf --host 0.0.0.0 --enable-lora --disable-log-requests --gpu-memory-utilization 0.85 --lora-modules lora-1=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-1 lora-2=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-2 lora-3=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-3 lora-4=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-4 lora-5=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-5 lora-6=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-6 lora-7=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-7 lora-8=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-8 lora-9=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-9 lora-10=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-10 lora-11=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-11 lora-12=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-12 lora-13=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-13 lora-14=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-14 lora-15=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-15 lora-16=/scratch/xiayao/models/lora/llama-7b-hf-lora-r16-16 --max-loras 8 --max-cpu-loras 64 --tensor-parallel-size 1 --enforce-eager --port 8081