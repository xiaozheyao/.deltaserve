python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-2-7b-hf --enable-delta --disable-log-requests --gpu-memory-utilization 0.85 --swap-modules delta-1=/scratch/xiayao/models/7b/full/vicuna-7b-v1.5-1 delta-2=/scratch/xiayao/models/7b/full/vicuna-7b-v1.5-2 delta-3=/scratch/xiayao/models/7b/full/vicuna-7b-v1.5-3 delta-4=/scratch/xiayao/models/7b/full/vicuna-7b-v1.5-4 delta-5=/scratch/xiayao/models/7b/full/vicuna-7b-v1.5-5 delta-6=/scratch/xiayao/models/7b/full/vicuna-7b-v1.5-6 delta-7=/scratch/xiayao/models/7b/full/vicuna-7b-v1.5-7 delta-8=/scratch/xiayao/models/7b/full/vicuna-7b-v1.5-8 meta-llama/Llama-2-7b-hf=meta-llama/Llama-2-7b-hf --tensor-parallel-size 2 --enforce-eager --max-deltas 0 --enable-swap --max-swap-slots 1 --max-cpu-models 4