/mnt/hwfile/huqinghao/miniconda3/bin/python
2024-05-12 09:33:37,239 - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-05-12 09:33:37,239 - INFO - Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-05-12 09:33:37,239 - INFO - NumExpr defaulting to 8 threads.
2024-05-12 09:33:38,133	INFO scripts.py:1182 -- Did not find any active Ray processes.

==========
== CUDA ==
==========

CUDA Version 12.1.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

*************************
** DEPRECATION NOTICE! **
*************************
THIS IMAGE IS DEPRECATED and is scheduled for DELETION.
    https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/support-policy.md

Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b48e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:160: UserWarning: Field "model_name_or_path" has conflict with protected namespace "model_".

You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
  warnings.warn(
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5270>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-12 09:33:50 api_server.py:219] vLLM API server version 0.3.3
INFO 05-12 09:33:50 api_server.py:220] args: Namespace(host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=[], delta_modules=[], swap_modules=[SwapModule(name='delta-1', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-1'), SwapModule(name='delta-2', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-2'), SwapModule(name='delta-3', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-3'), SwapModule(name='delta-4', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-4'), SwapModule(name='delta-5', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-5'), SwapModule(name='delta-6', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-6'), SwapModule(name='delta-7', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-7'), SwapModule(name='delta-8', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-8')], chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='auto', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, seed=0, swap_space=4, gpu_memory_utilization=0.85, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=True, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=64, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=32, enable_delta=False, max_deltas=0, max_cpu_deltas=32, max_delta_bitwidth=4, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_prefetch=False, scheduler_policy='fcfs', engine_use_ray=False, disable_log_requests=True, max_log_len=None)
2024-05-12 09:33:53,640	INFO worker.py:1749 -- Started a local Ray instance.
INFO 05-12 09:33:56 llm_engine.py:87] Initializing an LLM engine (v0.3.3) with config: model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, lora_config=None, delta_config=None, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b47c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5b40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6410>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6ce0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69adc7a30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6680>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5db0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b54e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4be0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b75b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4d60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b56c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5f90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6860>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6e90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7a90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b69b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b60e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5810>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4f10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b40a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4160>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5bd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b64a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7a90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69adc7730>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6fb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6da0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b64d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5c00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5240>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b62c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6b90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7160>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b78b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b75b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69adc7b80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7340>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6a10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6140>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5870>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7e80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5a50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6320>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6bf0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b70d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7640>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5180>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7bb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6710>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5e40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5f00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7e50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b67a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6f20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7400>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4df0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69adc79a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-12 09:43:41 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=23983)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7f88929b8e50>
[36m(RayWorkerVllm pid=23983)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=23983)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=23983)[0m     self.remove()
[36m(RayWorkerVllm pid=23983)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=23983)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=23983)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
[36m(RayWorkerVllm pid=24343)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7f6180128e50>
[36m(RayWorkerVllm pid=24343)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=24343)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=24343)[0m     self.remove()
[36m(RayWorkerVllm pid=24343)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=24343)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=24343)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5270>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=23983)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7f88929b8e50>
[36m(RayWorkerVllm pid=23983)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=23983)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=23983)[0m     self.remove()
[36m(RayWorkerVllm pid=23983)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=23983)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=23983)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b71f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7910>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6bc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b62f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9f87c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b63b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6c80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6ec0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7be0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9f8370>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5480>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4d90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7220>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6890>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5fc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9f80d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b60e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6e90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b52a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4c10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9f89d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69adc7bb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6c50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6b60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6290>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b58a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9f90c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b68c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7580>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b75e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4b80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9f8580>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7790>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4cd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7ac0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b65f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5f30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b56c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b66e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b6710>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7bb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5060>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b62c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69adc7dc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b5270>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7430>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7760>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b68f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4880>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b79d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b4d60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b7fd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69a9b77c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69adc7730>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=23983)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=23983)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=24343)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=24343)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=23983)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=23983)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=24171)[0m INFO 05-12 09:52:28 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=24343)[0m INFO 05-12 09:52:33 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=23983)[0m INFO 05-12 09:52:36 selector.py:16] Using FlashAttention backend.
INFO 05-12 09:52:50 model_runner.py:155] Loading model weights took 6.1114 GB
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe69adc7bb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=24343)[0m INFO 05-12 09:52:52 model_runner.py:155] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=23983)[0m INFO 05-12 09:52:52 model_runner.py:155] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=24171)[0m INFO 05-12 09:52:52 model_runner.py:155] Loading model weights took 6.1114 GB
INFO 05-12 09:53:04 ray_gpu_executor.py:266] # GPU blocks: 19075, # CPU blocks: 1310
INFO 05-12 09:53:07 block_manager.py:264] disable automatic prefix caching
WARNING 05-12 09:53:07 serving_chat.py:373] No chat template provided. Chat API will not work.
INFO:     Started server process [16482]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     ::1:57956 - "GET /sysinfo HTTP/1.1" 200 OK
Translating from base-model to /vllm/.idea/full_models/Llama-2-13b-hf
Warming up starts
{'id': 184, 'prompt': 'USER: hola\nASSISTANT:', 'timestamp': 0, 'model': 'delta-4', 'min_tokens': 10, 'max_tokens': 10}
INFO 05-12 09:53:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:09 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:53:14 api_server.py:155] waiting for model...
INFO 05-12 09:53:14 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:14 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:57958 - "POST /v1/completions HTTP/1.1" 200 OK
Warming up ends
Issuing queries
sending 1 queries at 0.1
sending 1 queries at 0.30000000000000004
sending 1 queries at 0.4
sending 2 queries at 0.5
sending 1 queries at 0.6000000000000001
sending 1 queries at 0.7000000000000001
sending 1 queries at 1.0
sending 1 queries at 1.3
sending 1 queries at 1.4000000000000001
sending 2 queries at 1.6
sending 1 queries at 1.7000000000000002
sending 4 queries at 2.0
sending 1 queries at 2.2
sending 1 queries at 2.4000000000000004
sending 1 queries at 2.6
sending 1 queries at 3.1
sending 1 queries at 3.2
sending 1 queries at 3.3000000000000003
sending 2 queries at 3.5
sending 2 queries at 3.6
sending 1 queries at 3.9000000000000004
sending 1 queries at 4.0
sending 2 queries at 4.1000000000000005
sending 2 queries at 4.3
sending 2 queries at 4.4
sending 1 queries at 4.6000000000000005
sending 1 queries at 4.7
sending 1 queries at 4.800000000000001
sending 1 queries at 5.1000000000000005
sending 1 queries at 5.2
sending 2 queries at 5.300000000000001
sending 2 queries at 5.5
sending 1 queries at 5.6000000000000005
sending 3 queries at 5.7
sending 2 queries at 5.800000000000001
sending 1 queries at 5.9
sending 1 queries at 6.0
sending 3 queries at 6.5
sending 1 queries at 6.6000000000000005
sending 2 queries at 6.7
sending 4 queries at 6.800000000000001
sending 4 queries at 7.0
sending 2 queries at 7.2
sending 2 queries at 7.5
sending 2 queries at 7.9
sending 1 queries at 8.4
sending 1 queries at 8.5
sending 2 queries at 8.6
sending 4 queries at 8.700000000000001
sending 3 queries at 8.8
sending 1 queries at 9.0
sending 2 queries at 9.1
sending 2 queries at 9.200000000000001
sending 1 queries at 9.3
sending 2 queries at 9.600000000000001
sending 1 queries at 9.700000000000001
sending 1 queries at 9.8
sending 2 queries at 9.9
sending 1 queries at 10.0
sending 2 queries at 10.100000000000001
sending 2 queries at 10.3
sending 2 queries at 10.4
sending 1 queries at 10.600000000000001
sending 1 queries at 10.9
sending 1 queries at 11.0
sending 1 queries at 11.100000000000001
sending 1 queries at 11.200000000000001
sending 2 queries at 11.3
sending 1 queries at 11.600000000000001
sending 1 queries at 11.700000000000001
sending 1 queries at 11.9
sending 1 queries at 12.0
sending 1 queries at 12.100000000000001
sending 2 queries at 12.3
sending 1 queries at 12.5
sending 1 queries at 12.600000000000001
sending 1 queries at 12.9
sending 1 queries at 13.0
sending 2 queries at 13.200000000000001
sending 1 queries at 13.600000000000001
sending 1 queries at 13.700000000000001
sending 1 queries at 13.8
sending 3 queries at 13.9
sending 1 queries at 14.0
sending 1 queries at 14.100000000000001
sending 3 queries at 14.200000000000001
sending 1 queries at 14.3
sending 1 queries at 14.4
sending 1 queries at 14.5
sending 1 queries at 14.600000000000001
sending 1 queries at 14.700000000000001
sending 1 queries at 14.8
sending 1 queries at 14.9
sending 1 queries at 15.100000000000001
sending 2 queries at 15.200000000000001
sending 1 queries at 15.5
sending 1 queries at 15.700000000000001
sending 2 queries at 15.8
sending 1 queries at 16.1
sending 1 queries at 16.2
sending 2 queries at 17.0
sending 2 queries at 17.2
sending 2 queries at 17.400000000000002
sending 1 queries at 17.6
sending 1 queries at 17.8
sending 3 queries at 17.900000000000002
sending 1 queries at 18.0
sending 1 queries at 18.1
sending 1 queries at 18.3
sending 1 queries at 18.5
sending 1 queries at 18.900000000000002
sending 2 queries at 19.1
sending 1 queries at 19.200000000000003
sending 2 queries at 19.3
sending 4 queries at 19.400000000000002
sending 2 queries at 19.6
sending 1 queries at 19.700000000000003
sending 1 queries at 20.0
sending 3 queries at 20.1
sending 2 queries at 20.3
sending 1 queries at 20.400000000000002
sending 1 queries at 20.700000000000003
sending 1 queries at 20.8
sending 1 queries at 20.900000000000002
sending 1 queries at 21.0
sending 1 queries at 21.1
sending 3 queries at 21.200000000000003
sending 1 queries at 21.3
sending 1 queries at 21.6
sending 1 queries at 21.700000000000003
sending 2 queries at 21.8
sending 3 queries at 21.900000000000002
sending 1 queries at 22.0
sending 1 queries at 22.1
sending 4 queries at 22.200000000000003
sending 1 queries at 22.3
sending 1 queries at 22.400000000000002
sending 1 queries at 22.5
sending 1 queries at 22.700000000000003
sending 1 queries at 23.200000000000003
sending 1 queries at 23.3
sending 3 queries at 23.400000000000002
sending 2 queries at 23.6
sending 1 queries at 23.700000000000003
sending 1 queries at 23.8
sending 1 queries at 24.0
sending 1 queries at 24.1
sending 1 queries at 24.3
sending 1 queries at 24.400000000000002
sending 1 queries at 24.5
sending 1 queries at 24.6
sending 1 queries at 24.900000000000002
sending 1 queries at 25.0
sending 1 queries at 25.1
sending 1 queries at 25.400000000000002
sending 1 queries at 25.5
sending 2 queries at 25.6
sending 3 queries at 25.700000000000003
sending 2 queries at 25.8
sending 2 queries at 25.900000000000002
sending 1 queries at 26.0
sending 2 queries at 26.200000000000003
sending 2 queries at 26.3
sending 2 queries at 26.5
sending 1 queries at 26.6
sending 3 queries at 26.700000000000003
sending 1 queries at 26.8
sending 1 queries at 27.1
sending 1 queries at 27.3
sending 1 queries at 27.400000000000002
sending 2 queries at 27.700000000000003
sending 1 queries at 27.8
sending 1 queries at 27.900000000000002
sending 1 queries at 28.200000000000003
sending 4 queries at 28.3
sending 1 queries at 28.6
sending 1 queries at 28.700000000000003
sending 1 queries at 28.900000000000002
sending 2 queries at 29.0
sending 2 queries at 29.1
sending 1 queries at 29.6
sending 2 queries at 29.8
INFO 05-12 09:53:14 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:14 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.7 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:155] waiting for model...
INFO 05-12 09:53:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:19 api_server.py:134] Waiting for reload lock...
INFO:     ::1:57990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:19 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:155] waiting for model...
INFO 05-12 09:53:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 metrics.py:276] Avg prompt throughput: 117.1 tokens/s, Avg generation throughput: 5.8 tokens/s, Running: 20 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:24 api_server.py:134] Waiting for reload lock...
INFO:     ::1:58034 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:24 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 metrics.py:276] Avg prompt throughput: 42.9 tokens/s, Avg generation throughput: 21.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58050 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:29 api_server.py:155] waiting for model...
INFO 05-12 09:53:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:29 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:30 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:30 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:30 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:30 api_server.py:134] Waiting for reload lock...
INFO:     ::1:58052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:30 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:53:35 api_server.py:155] waiting for model...
INFO 05-12 09:53:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 metrics.py:276] Avg prompt throughput: 7.3 tokens/s, Avg generation throughput: 126.7 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:155] waiting for model...
INFO 05-12 09:53:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:155] waiting for model...
INFO 05-12 09:53:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:35 api_server.py:134] Waiting for reload lock...
INFO:     ::1:58378 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:35 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 metrics.py:276] Avg prompt throughput: 9.7 tokens/s, Avg generation throughput: 88.7 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:40 api_server.py:155] waiting for model...
INFO 05-12 09:53:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:41 api_server.py:155] waiting for model...
INFO 05-12 09:53:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:41 api_server.py:155] waiting for model...
INFO 05-12 09:53:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:41 api_server.py:155] waiting for model...
INFO 05-12 09:53:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:41 api_server.py:155] waiting for model...
INFO 05-12 09:53:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:41 api_server.py:134] Waiting for reload lock...
INFO:     ::1:57972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:41 async_llm_engine.py:437] Reloading model to delta-2
total threads: 273
INFO 05-12 09:53:45 api_server.py:155] waiting for model...
INFO 05-12 09:53:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:45 metrics.py:276] Avg prompt throughput: 107.0 tokens/s, Avg generation throughput: 119.5 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO:     ::1:58504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:45 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:53:50 api_server.py:155] waiting for model...
INFO 05-12 09:53:50 api_server.py:163] requested model is loaded --> continuing...
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
Prefetching is disabled
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:155] waiting for model...
INFO 05-12 09:53:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:155] waiting for model...
INFO 05-12 09:53:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:155] waiting for model...
INFO 05-12 09:53:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 09:53:50 metrics.py:276] Avg prompt throughput: 30.1 tokens/s, Avg generation throughput: 29.7 tokens/s, Running: 48 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:57974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:51 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:53:55 api_server.py:155] waiting for model...
INFO 05-12 09:53:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:57982 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:55 api_server.py:155] waiting for model...
INFO 05-12 09:53:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:53:56 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 84.3 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:57986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:53:56 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:54:00 api_server.py:155] waiting for model...
INFO 05-12 09:54:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58542 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:00 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:54:05 api_server.py:155] waiting for model...
INFO 05-12 09:54:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:05 metrics.py:276] Avg prompt throughput: 3.5 tokens/s, Avg generation throughput: 24.7 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:57988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:05 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 09:54:10 api_server.py:155] waiting for model...
INFO 05-12 09:54:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:10 metrics.py:276] Avg prompt throughput: 14.1 tokens/s, Avg generation throughput: 65.6 tokens/s, Running: 47 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58500 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:10 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 09:54:15 api_server.py:155] waiting for model...
INFO 05-12 09:54:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58468 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:15 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:54:20 api_server.py:155] waiting for model...
INFO 05-12 09:54:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:20 metrics.py:276] Avg prompt throughput: 2.4 tokens/s, Avg generation throughput: 62.5 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:57980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:57996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:20 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 09:54:25 api_server.py:155] waiting for model...
INFO 05-12 09:54:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:25 metrics.py:276] Avg prompt throughput: 8.4 tokens/s, Avg generation throughput: 93.4 tokens/s, Running: 46 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58488 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:25 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 09:54:30 api_server.py:155] waiting for model...
INFO 05-12 09:54:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:57994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:30 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:54:34 api_server.py:155] waiting for model...
INFO 05-12 09:54:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:34 metrics.py:276] Avg prompt throughput: 5.2 tokens/s, Avg generation throughput: 24.2 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58462 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:34 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:54:39 api_server.py:155] waiting for model...
INFO 05-12 09:54:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:39 metrics.py:276] Avg prompt throughput: 11.2 tokens/s, Avg generation throughput: 18.3 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:39 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:54:44 api_server.py:155] waiting for model...
INFO 05-12 09:54:44 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:44 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 09:54:49 api_server.py:155] waiting for model...
INFO 05-12 09:54:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:49 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 14.6 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58508 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:49 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 09:54:53 api_server.py:155] waiting for model...
INFO 05-12 09:54:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:53 api_server.py:155] waiting for model...
INFO 05-12 09:54:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:54 metrics.py:276] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 54.3 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:54 api_server.py:155] waiting for model...
INFO 05-12 09:54:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:54 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:54:58 api_server.py:155] waiting for model...
INFO 05-12 09:54:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:54:59 metrics.py:276] Avg prompt throughput: 11.8 tokens/s, Avg generation throughput: 62.9 tokens/s, Running: 45 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:57976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:54:59 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 09:55:03 api_server.py:155] waiting for model...
INFO 05-12 09:55:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:03 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 09:55:08 api_server.py:155] waiting for model...
INFO 05-12 09:55:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.6 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:08 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:55:13 api_server.py:155] waiting for model...
INFO 05-12 09:55:13 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:13 metrics.py:276] Avg prompt throughput: 11.3 tokens/s, Avg generation throughput: 51.5 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:57966 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:13 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:55:17 api_server.py:155] waiting for model...
INFO 05-12 09:55:17 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:18 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:55:22 api_server.py:155] waiting for model...
INFO 05-12 09:55:22 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:22 metrics.py:276] Avg prompt throughput: 6.3 tokens/s, Avg generation throughput: 14.0 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58038 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:22 api_server.py:155] waiting for model...
INFO 05-12 09:55:22 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58457 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:23 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:55:28 api_server.py:155] waiting for model...
INFO 05-12 09:55:28 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:28 metrics.py:276] Avg prompt throughput: 10.7 tokens/s, Avg generation throughput: 95.2 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:28 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:55:33 api_server.py:155] waiting for model...
INFO 05-12 09:55:33 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:33 metrics.py:276] Avg prompt throughput: 7.6 tokens/s, Avg generation throughput: 17.5 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58016 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:33 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:55:38 api_server.py:155] waiting for model...
INFO 05-12 09:55:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:38 metrics.py:276] Avg prompt throughput: 5.8 tokens/s, Avg generation throughput: 33.5 tokens/s, Running: 42 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:38 api_server.py:155] waiting for model...
INFO 05-12 09:55:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:57964 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:38 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:55:43 api_server.py:155] waiting for model...
INFO 05-12 09:55:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:43 metrics.py:276] Avg prompt throughput: 6.8 tokens/s, Avg generation throughput: 79.8 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:43 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:55:48 api_server.py:155] waiting for model...
INFO 05-12 09:55:48 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:48 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 66.6 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%
INFO:     ::1:57984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:48 api_server.py:155] waiting for model...
INFO 05-12 09:55:48 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58008 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:49 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:55:53 api_server.py:155] waiting for model...
INFO 05-12 09:55:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:53 metrics.py:276] Avg prompt throughput: 10.6 tokens/s, Avg generation throughput: 75.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58556 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:53 api_server.py:155] waiting for model...
INFO 05-12 09:55:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58402 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:54 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:55:59 api_server.py:155] waiting for model...
INFO 05-12 09:55:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:55:59 metrics.py:276] Avg prompt throughput: 16.7 tokens/s, Avg generation throughput: 106.1 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:59 api_server.py:155] waiting for model...
INFO 05-12 09:55:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:55:59 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:56:04 api_server.py:155] waiting for model...
INFO 05-12 09:56:04 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:04 metrics.py:276] Avg prompt throughput: 8.7 tokens/s, Avg generation throughput: 55.9 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58112 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:04 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:56:09 api_server.py:155] waiting for model...
INFO 05-12 09:56:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:09 metrics.py:276] Avg prompt throughput: 20.1 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:09 api_server.py:155] waiting for model...
INFO 05-12 09:56:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:57968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:09 api_server.py:155] waiting for model...
INFO 05-12 09:56:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:09 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:56:14 api_server.py:155] waiting for model...
INFO 05-12 09:56:14 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:14 metrics.py:276] Avg prompt throughput: 13.8 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:15 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:56:19 api_server.py:155] waiting for model...
INFO 05-12 09:56:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:19 metrics.py:276] Avg prompt throughput: 8.0 tokens/s, Avg generation throughput: 84.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58418 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:20 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:56:25 api_server.py:155] waiting for model...
INFO 05-12 09:56:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:25 metrics.py:276] Avg prompt throughput: 3.7 tokens/s, Avg generation throughput: 71.1 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:25 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:56:29 api_server.py:155] waiting for model...
INFO 05-12 09:56:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:29 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:56:34 api_server.py:155] waiting for model...
INFO 05-12 09:56:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:34 metrics.py:276] Avg prompt throughput: 4.7 tokens/s, Avg generation throughput: 21.3 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:35 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 09:56:39 api_server.py:155] waiting for model...
INFO 05-12 09:56:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:39 metrics.py:276] Avg prompt throughput: 6.3 tokens/s, Avg generation throughput: 117.7 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:40 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:56:45 api_server.py:155] waiting for model...
INFO 05-12 09:56:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:45 metrics.py:276] Avg prompt throughput: 2.7 tokens/s, Avg generation throughput: 55.2 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58506 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:45 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:56:49 api_server.py:155] waiting for model...
INFO 05-12 09:56:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58024 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:49 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 09:56:54 api_server.py:155] waiting for model...
INFO 05-12 09:56:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:54 metrics.py:276] Avg prompt throughput: 7.0 tokens/s, Avg generation throughput: 8.8 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:54 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:56:59 api_server.py:155] waiting for model...
INFO 05-12 09:56:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:56:59 metrics.py:276] Avg prompt throughput: 3.1 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58552 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:56:59 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:57:04 api_server.py:155] waiting for model...
INFO 05-12 09:57:04 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:04 metrics.py:276] Avg prompt throughput: 65.9 tokens/s, Avg generation throughput: 8.3 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:05 api_server.py:155] waiting for model...
INFO 05-12 09:57:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58012 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:05 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 09:57:09 api_server.py:155] waiting for model...
INFO 05-12 09:57:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:09 metrics.py:276] Avg prompt throughput: 1.9 tokens/s, Avg generation throughput: 119.9 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:10 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:57:14 api_server.py:155] waiting for model...
INFO 05-12 09:57:14 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:14 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:57:19 api_server.py:155] waiting for model...
INFO 05-12 09:57:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:19 metrics.py:276] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:20 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 09:57:24 api_server.py:155] waiting for model...
INFO 05-12 09:57:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:24 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:57:29 api_server.py:155] waiting for model...
INFO 05-12 09:57:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:29 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 38.0 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%
INFO:     ::1:57978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:29 api_server.py:155] waiting for model...
INFO 05-12 09:57:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:29 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:57:34 api_server.py:155] waiting for model...
INFO 05-12 09:57:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:34 metrics.py:276] Avg prompt throughput: 6.3 tokens/s, Avg generation throughput: 86.6 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:34 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:57:39 api_server.py:155] waiting for model...
INFO 05-12 09:57:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:39 metrics.py:276] Avg prompt throughput: 7.4 tokens/s, Avg generation throughput: 74.0 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:39 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 09:57:44 api_server.py:155] waiting for model...
INFO 05-12 09:57:44 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:44 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 09:57:48 api_server.py:155] waiting for model...
INFO 05-12 09:57:48 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:48 metrics.py:276] Avg prompt throughput: 2.2 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 40 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%
INFO:     ::1:57970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:49 api_server.py:155] waiting for model...
INFO 05-12 09:57:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:49 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 09:57:53 api_server.py:155] waiting for model...
INFO 05-12 09:57:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:53 metrics.py:276] Avg prompt throughput: 10.4 tokens/s, Avg generation throughput: 73.8 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58108 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:54 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:57:58 api_server.py:155] waiting for model...
INFO 05-12 09:57:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:57:58 metrics.py:276] Avg prompt throughput: 10.0 tokens/s, Avg generation throughput: 57.4 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58138 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:59 api_server.py:155] waiting for model...
INFO 05-12 09:57:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:59 api_server.py:155] waiting for model...
INFO 05-12 09:57:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:57:59 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 09:58:04 api_server.py:155] waiting for model...
INFO 05-12 09:58:04 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:04 metrics.py:276] Avg prompt throughput: 7.3 tokens/s, Avg generation throughput: 104.8 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:04 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 09:58:09 api_server.py:155] waiting for model...
INFO 05-12 09:58:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:09 metrics.py:276] Avg prompt throughput: 4.7 tokens/s, Avg generation throughput: 137.0 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:09 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 09:58:14 api_server.py:155] waiting for model...
INFO 05-12 09:58:14 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:14 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:58:19 api_server.py:155] waiting for model...
INFO 05-12 09:58:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:19 metrics.py:276] Avg prompt throughput: 3.5 tokens/s, Avg generation throughput: 12.1 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:19 api_server.py:155] waiting for model...
INFO 05-12 09:58:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:19 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:58:24 api_server.py:155] waiting for model...
INFO 05-12 09:58:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:24 metrics.py:276] Avg prompt throughput: 9.2 tokens/s, Avg generation throughput: 59.0 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:24 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 09:58:29 api_server.py:155] waiting for model...
INFO 05-12 09:58:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:29 metrics.py:276] Avg prompt throughput: 3.7 tokens/s, Avg generation throughput: 43.8 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:29 api_server.py:155] waiting for model...
INFO 05-12 09:58:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:29 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:58:34 api_server.py:155] waiting for model...
INFO 05-12 09:58:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:34 metrics.py:276] Avg prompt throughput: 11.2 tokens/s, Avg generation throughput: 92.0 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:35 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 09:58:39 api_server.py:155] waiting for model...
INFO 05-12 09:58:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:39 metrics.py:276] Avg prompt throughput: 16.8 tokens/s, Avg generation throughput: 51.9 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:40 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:58:44 api_server.py:155] waiting for model...
INFO 05-12 09:58:44 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:44 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 36 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:45 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:58:49 api_server.py:155] waiting for model...
INFO 05-12 09:58:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:49 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:58:54 api_server.py:155] waiting for model...
INFO 05-12 09:58:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:58:54 metrics.py:276] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 15.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58496 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:54 api_server.py:155] waiting for model...
INFO 05-12 09:58:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:58:55 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 09:59:00 api_server.py:155] waiting for model...
INFO 05-12 09:59:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:00 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:00 api_server.py:155] waiting for model...
INFO 05-12 09:59:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:01 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:59:06 api_server.py:155] waiting for model...
INFO 05-12 09:59:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:06 metrics.py:276] Avg prompt throughput: 9.2 tokens/s, Avg generation throughput: 90.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:06 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 09:59:10 api_server.py:155] waiting for model...
INFO 05-12 09:59:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:11 metrics.py:276] Avg prompt throughput: 9.2 tokens/s, Avg generation throughput: 28.1 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:11 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:59:15 api_server.py:155] waiting for model...
INFO 05-12 09:59:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58171 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:15 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:59:20 api_server.py:155] waiting for model...
INFO 05-12 09:59:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:20 metrics.py:276] Avg prompt throughput: 1.8 tokens/s, Avg generation throughput: 3.6 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:21 api_server.py:155] waiting for model...
INFO 05-12 09:59:21 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:21 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 09:59:26 api_server.py:155] waiting for model...
INFO 05-12 09:59:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:26 metrics.py:276] Avg prompt throughput: 5.6 tokens/s, Avg generation throughput: 127.1 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:26 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:59:31 api_server.py:155] waiting for model...
INFO 05-12 09:59:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:31 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:59:35 api_server.py:155] waiting for model...
INFO 05-12 09:59:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:35 metrics.py:276] Avg prompt throughput: 5.1 tokens/s, Avg generation throughput: 25.1 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:36 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:59:40 api_server.py:155] waiting for model...
INFO 05-12 09:59:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:40 metrics.py:276] Avg prompt throughput: 47.7 tokens/s, Avg generation throughput: 27.2 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:41 api_server.py:155] waiting for model...
INFO 05-12 09:59:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58120 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:41 api_server.py:155] waiting for model...
INFO 05-12 09:59:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:57992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:41 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 09:59:46 api_server.py:155] waiting for model...
INFO 05-12 09:59:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:46 metrics.py:276] Avg prompt throughput: 45.3 tokens/s, Avg generation throughput: 46.6 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:46 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 09:59:51 api_server.py:155] waiting for model...
INFO 05-12 09:59:51 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:51 metrics.py:276] Avg prompt throughput: 11.1 tokens/s, Avg generation throughput: 33.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:51 api_server.py:155] waiting for model...
INFO 05-12 09:59:51 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:51 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 09:59:56 api_server.py:155] waiting for model...
INFO 05-12 09:59:56 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 09:59:56 metrics.py:276] Avg prompt throughput: 19.0 tokens/s, Avg generation throughput: 60.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 09:59:56 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:00:00 api_server.py:155] waiting for model...
INFO 05-12 10:00:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:00 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:00:05 api_server.py:155] waiting for model...
INFO 05-12 10:00:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:05 metrics.py:276] Avg prompt throughput: 4.4 tokens/s, Avg generation throughput: 10.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58082 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:05 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:00:10 api_server.py:155] waiting for model...
INFO 05-12 10:00:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58228 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:10 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:00:15 api_server.py:155] waiting for model...
INFO 05-12 10:00:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:15 metrics.py:276] Avg prompt throughput: 4.5 tokens/s, Avg generation throughput: 34.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:15 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:00:20 api_server.py:155] waiting for model...
INFO 05-12 10:00:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:20 metrics.py:276] Avg prompt throughput: 7.8 tokens/s, Avg generation throughput: 58.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:20 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:00:25 api_server.py:155] waiting for model...
INFO 05-12 10:00:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:25 metrics.py:276] Avg prompt throughput: 13.8 tokens/s, Avg generation throughput: 38.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:25 api_server.py:155] waiting for model...
INFO 05-12 10:00:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:25 api_server.py:155] waiting for model...
INFO 05-12 10:00:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58190 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:25 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:00:30 api_server.py:155] waiting for model...
INFO 05-12 10:00:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:30 metrics.py:276] Avg prompt throughput: 19.0 tokens/s, Avg generation throughput: 33.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:30 api_server.py:155] waiting for model...
INFO 05-12 10:00:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:30 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:00:35 api_server.py:155] waiting for model...
INFO 05-12 10:00:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:35 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 32.0 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:35 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:00:40 api_server.py:155] waiting for model...
INFO 05-12 10:00:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:40 metrics.py:276] Avg prompt throughput: 3.9 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:40 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:00:45 api_server.py:155] waiting for model...
INFO 05-12 10:00:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:45 metrics.py:276] Avg prompt throughput: 10.5 tokens/s, Avg generation throughput: 79.3 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:45 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:00:50 api_server.py:155] waiting for model...
INFO 05-12 10:00:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:50 metrics.py:276] Avg prompt throughput: 7.4 tokens/s, Avg generation throughput: 38.1 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:50 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:00:55 api_server.py:155] waiting for model...
INFO 05-12 10:00:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:00:55 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 35.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:00:55 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:01:00 api_server.py:155] waiting for model...
INFO 05-12 10:01:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:00 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 24.1 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:00 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:01:05 api_server.py:155] waiting for model...
INFO 05-12 10:01:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:05 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:01:10 api_server.py:155] waiting for model...
INFO 05-12 10:01:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:10 metrics.py:276] Avg prompt throughput: 4.9 tokens/s, Avg generation throughput: 9.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:10 api_server.py:155] waiting for model...
INFO 05-12 10:01:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:10 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:01:15 api_server.py:155] waiting for model...
INFO 05-12 10:01:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:15 metrics.py:276] Avg prompt throughput: 17.1 tokens/s, Avg generation throughput: 29.3 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:15 api_server.py:155] waiting for model...
INFO 05-12 10:01:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58510 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:16 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:01:20 api_server.py:155] waiting for model...
INFO 05-12 10:01:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:20 metrics.py:276] Avg prompt throughput: 2.9 tokens/s, Avg generation throughput: 49.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:21 api_server.py:155] waiting for model...
INFO 05-12 10:01:21 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:21 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:01:26 api_server.py:155] waiting for model...
INFO 05-12 10:01:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:26 metrics.py:276] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 48.8 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:26 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:01:30 api_server.py:155] waiting for model...
INFO 05-12 10:01:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:30 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:01:35 api_server.py:155] waiting for model...
INFO 05-12 10:01:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:35 metrics.py:276] Avg prompt throughput: 1.8 tokens/s, Avg generation throughput: 5.8 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:35 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:01:40 api_server.py:155] waiting for model...
INFO 05-12 10:01:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58314 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:40 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:01:45 api_server.py:155] waiting for model...
INFO 05-12 10:01:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:45 metrics.py:276] Avg prompt throughput: 7.2 tokens/s, Avg generation throughput: 12.1 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:45 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:01:49 api_server.py:155] waiting for model...
INFO 05-12 10:01:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:50 metrics.py:276] Avg prompt throughput: 9.8 tokens/s, Avg generation throughput: 50.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:50 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:01:55 api_server.py:155] waiting for model...
INFO 05-12 10:01:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:01:55 metrics.py:276] Avg prompt throughput: 5.2 tokens/s, Avg generation throughput: 22.4 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:01:55 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:02:00 api_server.py:155] waiting for model...
INFO 05-12 10:02:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:00 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:00 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:02:05 api_server.py:155] waiting for model...
INFO 05-12 10:02:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:05 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 66.2 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:05 api_server.py:155] waiting for model...
INFO 05-12 10:02:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:05 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:02:10 api_server.py:155] waiting for model...
INFO 05-12 10:02:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:10 metrics.py:276] Avg prompt throughput: 87.9 tokens/s, Avg generation throughput: 47.2 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:11 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:02:15 api_server.py:155] waiting for model...
INFO 05-12 10:02:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:15 metrics.py:276] Avg prompt throughput: 10.7 tokens/s, Avg generation throughput: 62.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:15 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:02:20 api_server.py:155] waiting for model...
INFO 05-12 10:02:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:20 metrics.py:276] Avg prompt throughput: 6.6 tokens/s, Avg generation throughput: 26.5 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:20 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:02:25 api_server.py:155] waiting for model...
INFO 05-12 10:02:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:25 metrics.py:276] Avg prompt throughput: 22.9 tokens/s, Avg generation throughput: 16.3 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58268 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:26 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:02:31 api_server.py:155] waiting for model...
INFO 05-12 10:02:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 88.2 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:31 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:02:36 api_server.py:155] waiting for model...
INFO 05-12 10:02:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:36 metrics.py:276] Avg prompt throughput: 3.9 tokens/s, Avg generation throughput: 62.3 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:36 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:02:41 api_server.py:155] waiting for model...
INFO 05-12 10:02:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:41 metrics.py:276] Avg prompt throughput: 11.0 tokens/s, Avg generation throughput: 26.1 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:58166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:41 api_server.py:155] waiting for model...
INFO 05-12 10:02:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58348 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:41 api_server.py:155] waiting for model...
INFO 05-12 10:02:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:42 api_server.py:155] waiting for model...
INFO 05-12 10:02:42 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58276 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:42 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:02:46 api_server.py:155] waiting for model...
INFO 05-12 10:02:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:47 metrics.py:276] Avg prompt throughput: 128.1 tokens/s, Avg generation throughput: 57.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:47 api_server.py:155] waiting for model...
INFO 05-12 10:02:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:47 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:02:52 api_server.py:155] waiting for model...
INFO 05-12 10:02:52 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:52 metrics.py:276] Avg prompt throughput: 10.1 tokens/s, Avg generation throughput: 49.9 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:52 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:02:57 api_server.py:155] waiting for model...
INFO 05-12 10:02:57 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:02:57 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 85.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:02:58 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:03:03 api_server.py:155] waiting for model...
INFO 05-12 10:03:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:03 metrics.py:276] Avg prompt throughput: 5.5 tokens/s, Avg generation throughput: 62.5 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:03 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:03:08 api_server.py:155] waiting for model...
INFO 05-12 10:03:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:08 metrics.py:276] Avg prompt throughput: 2.6 tokens/s, Avg generation throughput: 63.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:08 api_server.py:155] waiting for model...
INFO 05-12 10:03:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58324 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:09 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:03:13 api_server.py:155] waiting for model...
INFO 05-12 10:03:13 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:13 metrics.py:276] Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 90.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:14 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:03:18 api_server.py:155] waiting for model...
INFO 05-12 10:03:18 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:18 metrics.py:276] Avg prompt throughput: 10.3 tokens/s, Avg generation throughput: 29.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58370 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:19 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:03:23 api_server.py:155] waiting for model...
INFO 05-12 10:03:23 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:23 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:03:28 api_server.py:155] waiting for model...
INFO 05-12 10:03:28 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:28 metrics.py:276] Avg prompt throughput: 4.5 tokens/s, Avg generation throughput: 18.4 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:28 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:03:33 api_server.py:155] waiting for model...
INFO 05-12 10:03:33 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:33 metrics.py:276] Avg prompt throughput: 48.7 tokens/s, Avg generation throughput: 19.9 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58384 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:33 api_server.py:155] waiting for model...
INFO 05-12 10:03:33 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58338 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:33 api_server.py:155] waiting for model...
INFO 05-12 10:03:33 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58366 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:34 api_server.py:155] waiting for model...
INFO 05-12 10:03:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58372 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:35 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:03:40 api_server.py:155] waiting for model...
INFO 05-12 10:03:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:40 metrics.py:276] Avg prompt throughput: 86.7 tokens/s, Avg generation throughput: 179.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58392 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:40 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:03:45 api_server.py:155] waiting for model...
INFO 05-12 10:03:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:45 metrics.py:276] Avg prompt throughput: 9.0 tokens/s, Avg generation throughput: 24.2 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:45 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:03:50 api_server.py:155] waiting for model...
INFO 05-12 10:03:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:50 metrics.py:276] Avg prompt throughput: 27.6 tokens/s, Avg generation throughput: 20.3 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:50 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:03:55 api_server.py:155] waiting for model...
INFO 05-12 10:03:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:03:55 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 34.0 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58344 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:03:55 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:04:00 api_server.py:155] waiting for model...
INFO 05-12 10:04:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:00 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 20.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:01 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:04:06 api_server.py:155] waiting for model...
INFO 05-12 10:04:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:06 metrics.py:276] Avg prompt throughput: 6.9 tokens/s, Avg generation throughput: 72.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:06 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 10:04:10 api_server.py:155] waiting for model...
INFO 05-12 10:04:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58376 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:10 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 10:04:16 api_server.py:155] waiting for model...
INFO 05-12 10:04:16 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:16 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 19.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:16 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:04:21 api_server.py:155] waiting for model...
INFO 05-12 10:04:21 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:21 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:04:25 api_server.py:155] waiting for model...
INFO 05-12 10:04:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:25 metrics.py:276] Avg prompt throughput: 5.2 tokens/s, Avg generation throughput: 5.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58380 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:26 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:04:31 api_server.py:155] waiting for model...
INFO 05-12 10:04:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:31 metrics.py:276] Avg prompt throughput: 3.5 tokens/s, Avg generation throughput: 67.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:31 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:04:36 api_server.py:155] waiting for model...
INFO 05-12 10:04:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:36 metrics.py:276] Avg prompt throughput: 80.9 tokens/s, Avg generation throughput: 52.2 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:36 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 10:04:41 api_server.py:155] waiting for model...
INFO 05-12 10:04:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:41 metrics.py:276] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 60.7 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:42 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:04:47 api_server.py:155] waiting for model...
INFO 05-12 10:04:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:47 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 84.3 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58404 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:47 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:04:52 api_server.py:155] waiting for model...
INFO 05-12 10:04:52 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:52 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 81.8 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%
INFO:     ::1:58414 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:53 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:04:57 api_server.py:155] waiting for model...
INFO 05-12 10:04:57 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:04:57 metrics.py:276] Avg prompt throughput: 5.4 tokens/s, Avg generation throughput: 45.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:04:57 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:05:02 api_server.py:155] waiting for model...
INFO 05-12 10:05:02 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58368 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:02 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:05:07 api_server.py:155] waiting for model...
INFO 05-12 10:05:07 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:07 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 10.3 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:07 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:05:12 api_server.py:155] waiting for model...
INFO 05-12 10:05:12 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:12 metrics.py:276] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 14.3 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58410 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:12 api_server.py:155] waiting for model...
INFO 05-12 10:05:12 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58436 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:12 api_server.py:155] waiting for model...
INFO 05-12 10:05:12 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58426 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:13 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 10:05:18 api_server.py:155] waiting for model...
INFO 05-12 10:05:18 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:18 metrics.py:276] Avg prompt throughput: 9.4 tokens/s, Avg generation throughput: 75.0 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:58428 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:18 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:05:23 api_server.py:155] waiting for model...
INFO 05-12 10:05:23 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:23 metrics.py:276] Avg prompt throughput: 3.1 tokens/s, Avg generation throughput: 32.9 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%
INFO:     ::1:58352 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:23 api_server.py:155] waiting for model...
INFO 05-12 10:05:23 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58398 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:24 api_server.py:155] waiting for model...
INFO 05-12 10:05:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:24 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 10:05:29 api_server.py:155] waiting for model...
INFO 05-12 10:05:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:29 metrics.py:276] Avg prompt throughput: 65.0 tokens/s, Avg generation throughput: 87.9 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%
INFO:     ::1:58382 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:29 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:05:34 api_server.py:155] waiting for model...
INFO 05-12 10:05:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:34 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:05:38 api_server.py:155] waiting for model...
INFO 05-12 10:05:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:38 metrics.py:276] Avg prompt throughput: 7.0 tokens/s, Avg generation throughput: 7.5 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58422 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:39 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:05:43 api_server.py:155] waiting for model...
INFO 05-12 10:05:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58446 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:43 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:05:48 api_server.py:155] waiting for model...
INFO 05-12 10:05:48 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:48 metrics.py:276] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 12.7 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:49 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:05:54 api_server.py:155] waiting for model...
INFO 05-12 10:05:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:54 metrics.py:276] Avg prompt throughput: 2.4 tokens/s, Avg generation throughput: 103.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58408 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:54 api_server.py:155] waiting for model...
INFO 05-12 10:05:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58451 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:54 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:05:59 api_server.py:155] waiting for model...
INFO 05-12 10:05:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:05:59 metrics.py:276] Avg prompt throughput: 15.8 tokens/s, Avg generation throughput: 19.4 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58440 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:05:59 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:06:03 api_server.py:155] waiting for model...
INFO 05-12 10:06:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:04 metrics.py:276] Avg prompt throughput: 7.7 tokens/s, Avg generation throughput: 57.2 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58459 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:04 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:06:09 api_server.py:155] waiting for model...
INFO 05-12 10:06:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:09 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 47.8 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58394 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:09 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:06:14 api_server.py:155] waiting for model...
INFO 05-12 10:06:14 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:14 metrics.py:276] Avg prompt throughput: 9.4 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58412 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:14 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:06:19 api_server.py:155] waiting for model...
INFO 05-12 10:06:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:19 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 61.9 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58453 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:19 api_server.py:155] waiting for model...
INFO 05-12 10:06:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:19 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:06:24 api_server.py:155] waiting for model...
INFO 05-12 10:06:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:24 metrics.py:276] Avg prompt throughput: 14.4 tokens/s, Avg generation throughput: 57.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58465 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:24 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:06:29 api_server.py:155] waiting for model...
INFO 05-12 10:06:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:29 metrics.py:276] Avg prompt throughput: 67.4 tokens/s, Avg generation throughput: 19.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58482 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:29 api_server.py:155] waiting for model...
INFO 05-12 10:06:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58484 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:29 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:06:34 api_server.py:155] waiting for model...
INFO 05-12 10:06:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:34 metrics.py:276] Avg prompt throughput: 21.7 tokens/s, Avg generation throughput: 22.9 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:34 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:06:39 api_server.py:155] waiting for model...
INFO 05-12 10:06:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:39 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:06:44 api_server.py:155] waiting for model...
INFO 05-12 10:06:44 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:44 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.6 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58512 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:44 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:06:49 api_server.py:155] waiting for model...
INFO 05-12 10:06:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:49 metrics.py:276] Avg prompt throughput: 7.6 tokens/s, Avg generation throughput: 55.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58438 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:50 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:06:54 api_server.py:155] waiting for model...
INFO 05-12 10:06:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:06:54 metrics.py:276] Avg prompt throughput: 13.9 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:55 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:06:59 api_server.py:155] waiting for model...
INFO 05-12 10:06:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58406 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:06:59 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:07:04 api_server.py:155] waiting for model...
INFO 05-12 10:07:04 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:04 metrics.py:276] Avg prompt throughput: 9.9 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58476 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:05 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:07:10 api_server.py:155] waiting for model...
INFO 05-12 10:07:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:10 metrics.py:276] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 82.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58430 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:10 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:07:15 api_server.py:155] waiting for model...
INFO 05-12 10:07:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:15 metrics.py:276] Avg prompt throughput: 13.3 tokens/s, Avg generation throughput: 18.4 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:15 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:07:20 api_server.py:155] waiting for model...
INFO 05-12 10:07:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:20 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:58530 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:20 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:07:25 api_server.py:155] waiting for model...
INFO 05-12 10:07:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:25 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 18.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58354 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:25 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:07:30 api_server.py:155] waiting for model...
INFO 05-12 10:07:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:30 metrics.py:276] Avg prompt throughput: 5.2 tokens/s, Avg generation throughput: 31.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58534 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:31 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:07:35 api_server.py:155] waiting for model...
INFO 05-12 10:07:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:35 metrics.py:276] Avg prompt throughput: 4.9 tokens/s, Avg generation throughput: 56.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:36 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:07:40 api_server.py:155] waiting for model...
INFO 05-12 10:07:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58536 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:40 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:07:45 api_server.py:155] waiting for model...
INFO 05-12 10:07:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:45 metrics.py:276] Avg prompt throughput: 6.4 tokens/s, Avg generation throughput: 19.3 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58480 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:45 api_server.py:155] waiting for model...
INFO 05-12 10:07:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58514 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:46 api_server.py:155] waiting for model...
INFO 05-12 10:07:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58546 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:46 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:07:50 api_server.py:155] waiting for model...
INFO 05-12 10:07:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:50 metrics.py:276] Avg prompt throughput: 37.0 tokens/s, Avg generation throughput: 68.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:58420 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:51 api_server.py:155] waiting for model...
INFO 05-12 10:07:51 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58442 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:51 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:07:56 api_server.py:155] waiting for model...
INFO 05-12 10:07:56 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:07:56 metrics.py:276] Avg prompt throughput: 9.1 tokens/s, Avg generation throughput: 58.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:58374 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:07:56 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:08:01 api_server.py:155] waiting for model...
INFO 05-12 10:08:01 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:08:01 metrics.py:276] Avg prompt throughput: 9.4 tokens/s, Avg generation throughput: 22.8 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:58558 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:08:01 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:08:06 api_server.py:155] waiting for model...
INFO 05-12 10:08:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:58520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:08:06 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:08:11 api_server.py:155] waiting for model...
INFO 05-12 10:08:11 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:08:11 metrics.py:276] Avg prompt throughput: 3.1 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:58554 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58526 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58461 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58424 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58455 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58432 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58564 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58528 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58474 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58466 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:08:16 metrics.py:276] Avg prompt throughput: 8.8 tokens/s, Avg generation throughput: 447.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58566 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58562 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58524 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58532 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:08:21 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 215.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO:     ::1:58471 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58548 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:08:26 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 134.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%
INFO:     ::1:58538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58502 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:58522 - "POST /v1/completions HTTP/1.1" 200 OK
Results written to .artifact/benchmarks/results/a06d4d76-c17a-4a70-8578-adff6087d73e.jsonl
Killing process 16482...
/var/spool/slurmd/job3671401/slurm_script: line 42: 16448 Killed                  apptainer run --nv --home /mnt/petrelfs/huqinghao/xzyao/:/home/xiayao --bind /mnt/petrelfs/huqinghao/xzyao/code/vllm:/vllm --bind /mnt/petrelfs/huqinghao/xzyao/code/triteia:/triteia --env PYTHONPATH=/vllm:/triteia --env CUDA_LAUNCH_BLOCKING=1 --env TVM_TARGET=nvidia/nvidia-a100 --env BITBLAS_TARGET=nvidia/nvidia-a100 --env RAY_DEDUP_LOGS=0 --workdir /vllm /mnt/petrelfs/huqinghao/xzyao/images/deltaserve.sif python3 /vllm/vllm/entrypoints/openai/api_server.py --model /vllm/.idea/full_models/Llama-2-13b-hf --disable-log-requests --gpu-memory-utilization 0.85 --swap-modules delta-1=/vllm/.idea/full_models/Llama-2-13b-hf-1 delta-2=/vllm/.idea/full_models/Llama-2-13b-hf-2 delta-3=/vllm/.idea/full_models/Llama-2-13b-hf-3 delta-4=/vllm/.idea/full_models/Llama-2-13b-hf-4 delta-5=/vllm/.idea/full_models/Llama-2-13b-hf-5 delta-6=/vllm/.idea/full_models/Llama-2-13b-hf-6 delta-7=/vllm/.idea/full_models/Llama-2-13b-hf-7 delta-8=/vllm/.idea/full_models/Llama-2-13b-hf-8 --tensor-parallel-size 4 --enforce-eager --max-deltas 0
