/mnt/hwfile/huqinghao/miniconda3/bin/python
2024-05-16 23:45:47,126 - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-05-16 23:45:47,126 - INFO - Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-05-16 23:45:47,126 - INFO - NumExpr defaulting to 8 threads.
2024-05-16 23:45:48,633	INFO scripts.py:1182 -- Did not find any active Ray processes.

==========
== CUDA ==
==========

CUDA Version 12.1.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

*************************
** DEPRECATION NOTICE! **
*************************
THIS IMAGE IS DEPRECATED and is scheduled for DELETION.
    https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/support-policy.md

Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd57b4546d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd57b455450>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-16 23:46:02 api_server.py:191] vLLM API server version 0.3.3
INFO 05-16 23:46:02 api_server.py:192] args: Namespace(host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=[], delta_modules=[], swap_modules=[SwapModule(name='/vllm/.idea/full_models/Llama-2-13b-hf', local_path='/vllm/.idea/full_models/Llama-2-13b-hf'), SwapModule(name='delta-1', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-1'), SwapModule(name='delta-2', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-2'), SwapModule(name='delta-3', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-3'), SwapModule(name='delta-4', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-4'), SwapModule(name='delta-5', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-5'), SwapModule(name='delta-6', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-6'), SwapModule(name='delta-7', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-7'), SwapModule(name='delta-8', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-8'), SwapModule(name='delta-9', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-9'), SwapModule(name='delta-10', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-10'), SwapModule(name='delta-11', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-11'), SwapModule(name='delta-12', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-12'), SwapModule(name='delta-13', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-13'), SwapModule(name='delta-14', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-14'), SwapModule(name='delta-15', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-15'), SwapModule(name='delta-16', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-16'), SwapModule(name='delta-17', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-17'), SwapModule(name='delta-18', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-18'), SwapModule(name='delta-19', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-19'), SwapModule(name='delta-20', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-20'), SwapModule(name='delta-21', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-21'), SwapModule(name='delta-22', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-22'), SwapModule(name='delta-23', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-23'), SwapModule(name='delta-24', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-24'), SwapModule(name='delta-25', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-25'), SwapModule(name='delta-26', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-26'), SwapModule(name='delta-27', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-27'), SwapModule(name='delta-28', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-28'), SwapModule(name='delta-29', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-29'), SwapModule(name='delta-30', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-30'), SwapModule(name='delta-31', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-31'), SwapModule(name='delta-32', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-32'), SwapModule(name='delta-33', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-33'), SwapModule(name='delta-34', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-34'), SwapModule(name='delta-35', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-35'), SwapModule(name='delta-36', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-36'), SwapModule(name='delta-37', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-37'), SwapModule(name='delta-38', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-38'), SwapModule(name='delta-39', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-39'), SwapModule(name='delta-40', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-40'), SwapModule(name='delta-41', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-41'), SwapModule(name='delta-42', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-42'), SwapModule(name='delta-43', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-43'), SwapModule(name='delta-44', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-44'), SwapModule(name='delta-45', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-45'), SwapModule(name='delta-46', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-46'), SwapModule(name='delta-47', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-47'), SwapModule(name='delta-48', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-48'), SwapModule(name='delta-49', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-49'), SwapModule(name='delta-50', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-50'), SwapModule(name='delta-51', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-51'), SwapModule(name='delta-52', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-52'), SwapModule(name='delta-53', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-53'), SwapModule(name='delta-54', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-54'), SwapModule(name='delta-55', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-55'), SwapModule(name='delta-56', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-56'), SwapModule(name='delta-57', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-57'), SwapModule(name='delta-58', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-58'), SwapModule(name='delta-59', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-59'), SwapModule(name='delta-60', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-60'), SwapModule(name='delta-61', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-61'), SwapModule(name='delta-62', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-62'), SwapModule(name='delta-63', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-63'), SwapModule(name='delta-64', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-64')], chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='auto', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, seed=0, swap_space=4, gpu_memory_utilization=0.85, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=True, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=64, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=32, enable_delta=False, max_deltas=0, max_cpu_deltas=32, max_delta_bitwidth=4, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_prefetch=False, scheduler_policy='fcfs', max_swap_slots=8, max_cpu_models=18, enable_swap=True, engine_use_ray=False, disable_log_requests=True, max_log_len=None)
2024-05-16 23:46:05,710	INFO worker.py:1749 -- Started a local Ray instance.
INFO 05-16 23:46:08 llm_engine.py:90] Initializing an LLM engine (v0.3.3) with config: model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, lora_config=None, delta_config=None, swap_config=SwapConfig(max_packed_model=8, max_cpu_model=18), max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd57b455d20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd57b455150>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-16 23:46:19 selector.py:16] Using FlashAttention backend.
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd57b454880>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:46:22 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:46:22 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:46:22 selector.py:16] Using FlashAttention backend.
INFO 05-16 23:46:35 model_runner.py:161] Loading model weights took 6.1114 GB
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd57b4565f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd57b456ec0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:46:36 model_runner.py:161] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:46:36 model_runner.py:161] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:46:36 model_runner.py:161] Loading model weights took 6.1114 GB
INFO 05-16 23:46:50 ray_gpu_executor.py:275] # GPU blocks: 3146, # CPU blocks: 1310
INFO 05-16 23:46:53 block_manager.py:264] disable automatic prefix caching
WARNING 05-16 23:46:53 serving_chat.py:373] No chat template provided. Chat API will not work.
INFO:     Started server process [109275]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     ::1:35738 - "GET /sysinfo HTTP/1.1" 200 OK
Translating from base-model to /vllm/.idea/full_models/Llama-2-13b-hf
Warming up starts
{'id': 35, 'prompt': 'USER: what is the current country leading in natural water resource?\nASSISTANT:', 'timestamp': 0, 'model': 'delta-4', 'min_tokens': 102, 'max_tokens': 102}
Prefetching is disabled
INFO 05-16 23:47:00 models.py:164] Disk -> CPU: Loaded in 1.296 seconds
INFO 05-16 23:47:02 worker_manager.py:250] [1715874422.093239] CPU -> GPU time: 1.5147
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:47:04 models.py:164] Disk -> CPU: Loaded in 5.121 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:47:04 models.py:164] Disk -> CPU: Loaded in 5.450 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:47:04 models.py:164] Disk -> CPU: Loaded in 5.536 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:47:06 worker_manager.py:250] [1715874426.033795] CPU -> GPU time: 1.6291
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:47:06 worker_manager.py:250] [1715874426.7983308] CPU -> GPU time: 1.9788
INFO 05-16 23:47:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:47:08 worker_manager.py:250] [1715874428.5265257] CPU -> GPU time: 3.7923
INFO 05-16 23:47:13 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 5.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-16 23:47:18 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO 05-16 23:47:23 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO:     ::1:35740 - "POST /v1/completions HTTP/1.1" 200 OK
Warming up ends
Issuing queries
sending 1 queries at 0.4
sending 1 queries at 1.1
sending 1 queries at 1.5
sending 1 queries at 1.9000000000000001
sending 1 queries at 2.2
sending 1 queries at 2.7
sending 1 queries at 3.0
sending 1 queries at 4.1000000000000005
sending 1 queries at 5.800000000000001
sending 1 queries at 6.0
sending 1 queries at 6.800000000000001
sending 1 queries at 7.2
sending 1 queries at 7.6000000000000005
sending 2 queries at 8.9
sending 2 queries at 9.0
sending 1 queries at 9.9
sending 1 queries at 10.600000000000001
sending 1 queries at 11.700000000000001
sending 1 queries at 13.600000000000001
sending 1 queries at 14.4
sending 1 queries at 14.700000000000001
sending 2 queries at 15.5
sending 1 queries at 16.0
sending 1 queries at 16.1
sending 1 queries at 17.6
sending 1 queries at 17.900000000000002
sending 1 queries at 18.2
sending 1 queries at 18.3
sending 1 queries at 19.1
sending 1 queries at 19.400000000000002
sending 2 queries at 19.8
sending 1 queries at 20.3
sending 1 queries at 20.8
sending 1 queries at 21.3
sending 1 queries at 22.700000000000003
sending 1 queries at 23.3
sending 1 queries at 23.5
sending 1 queries at 23.8
sending 2 queries at 24.400000000000002
sending 1 queries at 25.0
sending 1 queries at 25.5
sending 1 queries at 25.6
sending 1 queries at 25.700000000000003
sending 1 queries at 25.900000000000002
sending 1 queries at 26.1
sending 1 queries at 26.5
sending 1 queries at 26.8
sending 2 queries at 29.1
sending 1 queries at 29.200000000000003
sending 1 queries at 29.3
sending 1 queries at 29.8
sending 1 queries at 30.0
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
INFO 05-16 23:47:38 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
INFO 05-16 23:47:48 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
total threads: 58
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
Prefetching is disabled
INFO 05-16 23:47:58 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-16 23:48:02 models.py:164] Disk -> CPU: Loaded in 35.057 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:48:04 models.py:164] Disk -> CPU: Loaded in 37.061 seconds
INFO 05-16 23:48:10 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:48:07 models.py:164] Disk -> CPU: Loaded in 39.817 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:48:09 models.py:164] Disk -> CPU: Loaded in 42.098 seconds
INFO 05-16 23:48:12 models.py:164] Disk -> CPU: Loaded in 1.155 seconds
INFO 05-16 23:48:14 models.py:164] Disk -> CPU: Loaded in 1.180 seconds
INFO 05-16 23:48:16 models.py:164] Disk -> CPU: Loaded in 1.296 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:48:16 models.py:164] Disk -> CPU: Loaded in 5.528 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:48:16 models.py:164] Disk -> CPU: Loaded in 5.668 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:48:16 models.py:164] Disk -> CPU: Loaded in 5.639 seconds
INFO 05-16 23:48:18 models.py:164] Disk -> CPU: Loaded in 1.317 seconds
INFO 05-16 23:48:20 models.py:164] Disk -> CPU: Loaded in 1.247 seconds
INFO 05-16 23:48:20 metrics.py:276] Avg prompt throughput: 2.1 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:48:23 models.py:164] Disk -> CPU: Loaded in 5.492 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:48:23 models.py:164] Disk -> CPU: Loaded in 5.445 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:48:23 models.py:164] Disk -> CPU: Loaded in 5.301 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:48:29 models.py:164] Disk -> CPU: Loaded in 5.285 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:48:30 models.py:164] Disk -> CPU: Loaded in 5.832 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:48:30 models.py:164] Disk -> CPU: Loaded in 5.258 seconds
INFO 05-16 23:48:30 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:48:36 models.py:164] Disk -> CPU: Loaded in 5.224 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:48:36 models.py:164] Disk -> CPU: Loaded in 5.179 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:48:37 models.py:164] Disk -> CPU: Loaded in 6.014 seconds
INFO 05-16 23:48:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:48:42 models.py:164] Disk -> CPU: Loaded in 5.142 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:48:42 models.py:164] Disk -> CPU: Loaded in 5.156 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:48:44 models.py:164] Disk -> CPU: Loaded in 5.924 seconds
INFO 05-16 23:48:50 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%
INFO 05-16 23:48:53 models.py:164] Disk -> CPU: Loaded in 32.408 seconds
INFO 05-16 23:49:00 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:49:10 models.py:164] Disk -> CPU: Loaded in 27.072 seconds
INFO 05-16 23:49:10 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 44 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:49:14 models.py:164] Disk -> CPU: Loaded in 32.131 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:49:16 models.py:164] Disk -> CPU: Loaded in 30.791 seconds
INFO 05-16 23:49:18 metrics.py:276] Avg prompt throughput: 164.8 tokens/s, Avg generation throughput: 5.8 tokens/s, Running: 43 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO:     ::1:36230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:49:24 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 36.1 tokens/s, Running: 38 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO:     ::1:36270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:49:29 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 32.6 tokens/s, Running: 35 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO:     ::1:36272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:49:35 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 05-16 23:49:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 24.4 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 05-16 23:49:46 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 34.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%
INFO 05-16 23:49:52 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 30.1 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%
INFO:     ::1:36248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:49:57 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 05-16 23:50:03 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO:     ::1:36194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:50:09 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%
INFO:     ::1:36244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:50:14 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 26.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 05-16 23:50:20 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 25.8 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 05-16 23:50:25 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 26.2 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO:     ::1:36130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:50:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 25.1 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO:     ::1:36324 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:50:37 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 22.0 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO:     ::1:36296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:50:42 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 22.1 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 05-16 23:50:48 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 20.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%
INFO:     ::1:36218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:50:54 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 21.3 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 05-16 23:50:59 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 20.4 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%
INFO 05-16 23:51:05 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 20.2 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.9%, CPU KV cache usage: 0.0%
INFO 05-16 23:51:10 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 17.1 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 6.1%, CPU KV cache usage: 0.0%
INFO:     ::1:36240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36276 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36157 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:51:16 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 21.9 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 05-16 23:51:22 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 17.1 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO:     ::1:36204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:51:27 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 17.0 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:51:33 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 16.3 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 05-16 23:51:38 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 16.2 tokens/s, Running: 18 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%
INFO:     ::1:36292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:51:44 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 15.8 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%
INFO 05-16 23:51:49 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 15.3 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%
INFO:     ::1:36106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:51:55 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 15.0 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%
INFO 05-16 23:52:00 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 16 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.7%, CPU KV cache usage: 0.0%
INFO:     ::1:36260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:52:06 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 14.3 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO:     ::1:36300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:52:11 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO:     ::1:36252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:52:17 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 05-16 23:52:22 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 14 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO:     ::1:36076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:52:30 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.2 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 13 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%
INFO 05-16 23:52:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 13 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%
INFO 05-16 23:52:50 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 13 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%
INFO 05-16 23:52:58 models.py:164] Disk -> CPU: Loaded in 32.236 seconds
INFO 05-16 23:53:00 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 13 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:53:03 models.py:164] Disk -> CPU: Loaded in 36.695 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:53:05 models.py:164] Disk -> CPU: Loaded in 39.117 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:53:06 models.py:164] Disk -> CPU: Loaded in 40.485 seconds
INFO 05-16 23:53:08 metrics.py:276] Avg prompt throughput: 2.4 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 13 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%
INFO:     ::1:36278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:53:14 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.9 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 13 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 05-16 23:53:20 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.2 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 13 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO:     ::1:36314 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:53:21 models.py:164] Disk -> CPU: Loaded in 1.608 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:53:25 models.py:164] Disk -> CPU: Loaded in 5.205 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:53:25 models.py:164] Disk -> CPU: Loaded in 5.309 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:53:25 models.py:164] Disk -> CPU: Loaded in 5.442 seconds
INFO 05-16 23:53:26 metrics.py:276] Avg prompt throughput: 19.7 tokens/s, Avg generation throughput: 0.4 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 10 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%
INFO 05-16 23:53:32 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 10 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%
INFO:     ::1:36304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:53:38 models.py:164] Disk -> CPU: Loaded in 1.288 seconds
INFO 05-16 23:53:43 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.2 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 8 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:53:42 models.py:164] Disk -> CPU: Loaded in 5.263 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:53:42 models.py:164] Disk -> CPU: Loaded in 5.339 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:53:42 models.py:164] Disk -> CPU: Loaded in 5.352 seconds
INFO 05-16 23:53:48 metrics.py:276] Avg prompt throughput: 7.3 tokens/s, Avg generation throughput: 15.2 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 8 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%
INFO 05-16 23:53:54 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 15.1 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 8 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 05-16 23:53:59 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 15.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 8 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO:     ::1:36114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:54:13 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3.2 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%
INFO 05-16 23:54:23 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%
INFO 05-16 23:54:31 models.py:164] Disk -> CPU: Loaded in 28.326 seconds
INFO 05-16 23:54:41 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.8%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:54:35 models.py:164] Disk -> CPU: Loaded in 32.443 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:54:37 models.py:164] Disk -> CPU: Loaded in 35.217 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:54:40 models.py:164] Disk -> CPU: Loaded in 37.722 seconds
INFO 05-16 23:54:46 metrics.py:276] Avg prompt throughput: 5.6 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 05-16 23:54:52 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 15.4 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 05-16 23:54:57 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 15.5 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%
INFO:     ::1:36302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:55:02 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 5.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:55:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 14.0 tokens/s, Running: 14 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 5.5%, CPU KV cache usage: 0.0%
INFO:     ::1:36318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:55:13 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 5.0%, CPU KV cache usage: 0.0%
INFO 05-16 23:55:19 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.4 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 05-16 23:55:25 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO:     ::1:36168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:55:30 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.1 tokens/s, Running: 12 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 05-16 23:55:36 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.0 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%
INFO:     ::1:36250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:55:42 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.1 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%
INFO:     ::1:36242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:55:48 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 05-16 23:55:54 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.6%, CPU KV cache usage: 0.0%
INFO 05-16 23:56:00 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO:     ::1:36264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:56:05 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%
INFO 05-16 23:56:11 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:56:16 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.4%, CPU KV cache usage: 0.0%
INFO 05-16 23:56:22 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO:     ::1:36126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:36312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:56:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:56:41 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:56:51 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:56:58 models.py:164] Disk -> CPU: Loaded in 32.631 seconds
INFO 05-16 23:57:01 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:57:02 models.py:164] Disk -> CPU: Loaded in 36.341 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:57:10 models.py:164] Disk -> CPU: Loaded in 45.195 seconds
INFO 05-16 23:57:11 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:57:14 models.py:164] Disk -> CPU: Loaded in 48.328 seconds
INFO 05-16 23:57:21 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:57:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:57:41 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:57:41 models.py:164] Disk -> CPU: Loaded in 40.946 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:57:45 models.py:164] Disk -> CPU: Loaded in 42.500 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:57:47 models.py:164] Disk -> CPU: Loaded in 32.836 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:57:50 models.py:164] Disk -> CPU: Loaded in 38.343 seconds
INFO 05-16 23:57:51 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-16 23:57:59 metrics.py:276] Avg prompt throughput: 6.8 tokens/s, Avg generation throughput: 1.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO:     ::1:36268 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:58:11 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 05-16 23:58:21 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 05-16 23:58:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 05-16 23:58:39 models.py:164] Disk -> CPU: Loaded in 36.131 seconds
INFO 05-16 23:58:41 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119959)[0m INFO 05-16 23:58:42 models.py:164] Disk -> CPU: Loaded in 38.696 seconds
INFO 05-16 23:58:52 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119757)[0m INFO 05-16 23:58:49 models.py:164] Disk -> CPU: Loaded in 45.893 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-16 23:58:51 models.py:164] Disk -> CPU: Loaded in 48.395 seconds
INFO 05-16 23:59:02 metrics.py:276] Avg prompt throughput: 1.9 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 05-16 23:59:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 05-16 23:59:14 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
INFO 05-16 23:59:20 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 05-16 23:59:25 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%
INFO 05-16 23:59:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 4 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO:     ::1:36284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-16 23:59:42 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 05-16 23:59:52 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 05-17 00:00:02 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 05-17 00:00:05 models.py:164] Disk -> CPU: Loaded in 30.892 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-17 00:00:07 models.py:164] Disk -> CPU: Loaded in 33.189 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-17 00:00:07 models.py:164] Disk -> CPU: Loaded in 33.211 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-17 00:00:07 models.py:164] Disk -> CPU: Loaded in 33.189 seconds
INFO 05-17 00:00:08 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 0.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 05-17 00:00:22 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 05-17 00:00:28 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 3.9%, CPU KV cache usage: 0.0%
INFO 05-17 00:00:34 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.5 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%
INFO 05-17 00:00:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.2 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 4.1%, CPU KV cache usage: 0.0%
INFO:     ::1:36288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:00:52 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
INFO 05-17 00:01:02 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
INFO 05-17 00:01:12 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
INFO 05-17 00:01:19 models.py:164] Disk -> CPU: Loaded in 35.369 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-17 00:01:23 models.py:164] Disk -> CPU: Loaded in 38.938 seconds
INFO 05-17 00:01:27 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119757)[0m INFO 05-17 00:01:25 models.py:164] Disk -> CPU: Loaded in 40.808 seconds
[36m(RayWorkerVllm pid=119480)[0m INFO 05-17 00:01:27 models.py:164] Disk -> CPU: Loaded in 43.014 seconds
INFO 05-17 00:01:33 metrics.py:276] Avg prompt throughput: 9.5 tokens/s, Avg generation throughput: 5.9 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO:     ::1:36246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:01:47 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.7 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-17 00:01:57 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-17 00:02:06 models.py:164] Disk -> CPU: Loaded in 31.875 seconds
INFO 05-17 00:02:07 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-17 00:02:20 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
[36m(RayWorkerVllm pid=119480)[0m INFO 05-17 00:02:12 models.py:164] Disk -> CPU: Loaded in 38.015 seconds
[36m(RayWorkerVllm pid=119959)[0m INFO 05-17 00:02:17 models.py:164] Disk -> CPU: Loaded in 42.984 seconds
[36m(RayWorkerVllm pid=119757)[0m INFO 05-17 00:02:19 models.py:164] Disk -> CPU: Loaded in 45.252 seconds
INFO 05-17 00:02:30 metrics.py:276] Avg prompt throughput: 1.7 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-17 00:02:36 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.4 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 05-17 00:02:41 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.3 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
INFO 05-17 00:02:47 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO:     ::1:36294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:02:53 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.1 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 05-17 00:02:59 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.3 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:05 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.2%, CPU KV cache usage: 0.0%
INFO:     ::1:36308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:03:10 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.9 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:16 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.3 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:22 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.1 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:28 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.1 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:34 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:39 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.2 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.7%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:45 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.1 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:51 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 05-17 00:03:57 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.1 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO:     ::1:36236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:04:03 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.1 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
INFO:     ::1:36306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:04:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.9 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 05-17 00:04:13 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 05-17 00:04:18 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.5%, CPU KV cache usage: 0.0%
INFO:     ::1:36232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:04:24 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.7 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 05-17 00:04:29 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.6 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO:     ::1:36322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:04:34 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO 05-17 00:04:39 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 05-17 00:04:45 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%
INFO 05-17 00:04:50 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 05-17 00:04:55 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 05-17 00:05:01 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.3%, CPU KV cache usage: 0.0%
INFO 05-17 00:05:06 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 05-17 00:05:11 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 05-17 00:05:16 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 05-17 00:05:22 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.6%, CPU KV cache usage: 0.0%
INFO:     ::1:36298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:05:27 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.1%, CPU KV cache usage: 0.0%
INFO 05-17 00:05:32 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO:     ::1:36256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:05:37 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 05-17 00:05:42 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 05-17 00:05:48 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:36290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-17 00:05:53 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%
INFO:     ::1:36280 - "POST /v1/completions HTTP/1.1" 200 OK
Results written to .artifact/benchmarks/results/6e930b22-ea34-468d-a0bb-568eebbb61d9.jsonl
Killing process 109275...
/var/spool/slurmd/job3676312/slurm_script: line 42: 109243 Killed                  apptainer run --nv --home /mnt/petrelfs/huqinghao/xzyao/:/home/xiayao --bind /mnt/petrelfs/huqinghao/xzyao/code/vllm:/vllm --bind /mnt/petrelfs/huqinghao/xzyao/code/triteia:/triteia --env PYTHONPATH=/vllm:/triteia --env CUDA_LAUNCH_BLOCKING=1 --env TVM_TARGET=nvidia/nvidia-a100 --env BITBLAS_TARGET=nvidia/nvidia-a100 --env RAY_DEDUP_LOGS=0 --workdir /vllm /mnt/petrelfs/huqinghao/xzyao/images/deltaserve.sif python3 /vllm/vllm/entrypoints/openai/api_server.py --model /vllm/.idea/full_models/Llama-2-13b-hf --disable-log-requests --gpu-memory-utilization 0.85 --swap-modules /vllm/.idea/full_models/Llama-2-13b-hf=/vllm/.idea/full_models/Llama-2-13b-hf delta-1=/vllm/.idea/full_models/Llama-2-13b-hf-1 delta-2=/vllm/.idea/full_models/Llama-2-13b-hf-2 delta-3=/vllm/.idea/full_models/Llama-2-13b-hf-3 delta-4=/vllm/.idea/full_models/Llama-2-13b-hf-4 delta-5=/vllm/.idea/full_models/Llama-2-13b-hf-5 delta-6=/vllm/.idea/full_models/Llama-2-13b-hf-6 delta-7=/vllm/.idea/full_models/Llama-2-13b-hf-7 delta-8=/vllm/.idea/full_models/Llama-2-13b-hf-8 delta-9=/vllm/.idea/full_models/Llama-2-13b-hf-9 delta-10=/vllm/.idea/full_models/Llama-2-13b-hf-10 delta-11=/vllm/.idea/full_models/Llama-2-13b-hf-11 delta-12=/vllm/.idea/full_models/Llama-2-13b-hf-12 delta-13=/vllm/.idea/full_models/Llama-2-13b-hf-13 delta-14=/vllm/.idea/full_models/Llama-2-13b-hf-14 delta-15=/vllm/.idea/full_models/Llama-2-13b-hf-15 delta-16=/vllm/.idea/full_models/Llama-2-13b-hf-16 delta-17=/vllm/.idea/full_models/Llama-2-13b-hf-17 delta-18=/vllm/.idea/full_models/Llama-2-13b-hf-18 delta-19=/vllm/.idea/full_models/Llama-2-13b-hf-19 delta-20=/vllm/.idea/full_models/Llama-2-13b-hf-20 delta-21=/vllm/.idea/full_models/Llama-2-13b-hf-21 delta-22=/vllm/.idea/full_models/Llama-2-13b-hf-22 delta-23=/vllm/.idea/full_models/Llama-2-13b-hf-23 delta-24=/vllm/.idea/full_models/Llama-2-13b-hf-24 delta-25=/vllm/.idea/full_models/Llama-2-13b-hf-25 delta-26=/vllm/.idea/full_models/Llama-2-13b-hf-26 delta-27=/vllm/.idea/full_models/Llama-2-13b-hf-27 delta-28=/vllm/.idea/full_models/Llama-2-13b-hf-28 delta-29=/vllm/.idea/full_models/Llama-2-13b-hf-29 delta-30=/vllm/.idea/full_models/Llama-2-13b-hf-30 delta-31=/vllm/.idea/full_models/Llama-2-13b-hf-31 delta-32=/vllm/.idea/full_models/Llama-2-13b-hf-32 delta-33=/vllm/.idea/full_models/Llama-2-13b-hf-33 delta-34=/vllm/.idea/full_models/Llama-2-13b-hf-34 delta-35=/vllm/.idea/full_models/Llama-2-13b-hf-35 delta-36=/vllm/.idea/full_models/Llama-2-13b-hf-36 delta-37=/vllm/.idea/full_models/Llama-2-13b-hf-37 delta-38=/vllm/.idea/full_models/Llama-2-13b-hf-38 delta-39=/vllm/.idea/full_models/Llama-2-13b-hf-39 delta-40=/vllm/.idea/full_models/Llama-2-13b-hf-40 delta-41=/vllm/.idea/full_models/Llama-2-13b-hf-41 delta-42=/vllm/.idea/full_models/Llama-2-13b-hf-42 delta-43=/vllm/.idea/full_models/Llama-2-13b-hf-43 delta-44=/vllm/.idea/full_models/Llama-2-13b-hf-44 delta-45=/vllm/.idea/full_models/Llama-2-13b-hf-45 delta-46=/vllm/.idea/full_models/Llama-2-13b-hf-46 delta-47=/vllm/.idea/full_models/Llama-2-13b-hf-47 delta-48=/vllm/.idea/full_models/Llama-2-13b-hf-48 delta-49=/vllm/.idea/full_models/Llama-2-13b-hf-49 delta-50=/vllm/.idea/full_models/Llama-2-13b-hf-50 delta-51=/vllm/.idea/full_models/Llama-2-13b-hf-51 delta-52=/vllm/.idea/full_models/Llama-2-13b-hf-52 delta-53=/vllm/.idea/full_models/Llama-2-13b-hf-53 delta-54=/vllm/.idea/full_models/Llama-2-13b-hf-54 delta-55=/vllm/.idea/full_models/Llama-2-13b-hf-55 delta-56=/vllm/.idea/full_models/Llama-2-13b-hf-56 delta-57=/vllm/.idea/full_models/Llama-2-13b-hf-57 delta-58=/vllm/.idea/full_models/Llama-2-13b-hf-58 delta-59=/vllm/.idea/full_models/Llama-2-13b-hf-59 delta-60=/vllm/.idea/full_models/Llama-2-13b-hf-60 delta-61=/vllm/.idea/full_models/Llama-2-13b-hf-61 delta-62=/vllm/.idea/full_models/Llama-2-13b-hf-62 delta-63=/vllm/.idea/full_models/Llama-2-13b-hf-63 delta-64=/vllm/.idea/full_models/Llama-2-13b-hf-64 --tensor-parallel-size 4 --enforce-eager --max-deltas 0 --enable-swap --max-swap-slots 8 --max-cpu-models 18
