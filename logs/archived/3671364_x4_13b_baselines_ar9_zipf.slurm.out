/mnt/hwfile/huqinghao/miniconda3/bin/python
2024-05-12 04:30:10,442 - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-05-12 04:30:10,442 - INFO - Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-05-12 04:30:10,442 - INFO - NumExpr defaulting to 8 threads.
2024-05-12 04:30:11,384	INFO scripts.py:1182 -- Did not find any active Ray processes.

==========
== CUDA ==
==========

CUDA Version 12.1.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1cac0>: Failed to establish a new connection: [Errno 111] Connection refused'))

*************************
** DEPRECATION NOTICE! **
*************************
THIS IMAGE IS DEPRECATED and is scheduled for DELETION.
    https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/support-policy.md

/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:160: UserWarning: Field "model_name_or_path" has conflict with protected namespace "model_".

You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
  warnings.warn(
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d450>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-12 04:30:23 api_server.py:212] vLLM API server version 0.3.3
INFO 05-12 04:30:23 api_server.py:213] args: Namespace(host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=[], delta_modules=[], swap_modules=[SwapModule(name='delta-1', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-1'), SwapModule(name='delta-2', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-2'), SwapModule(name='delta-3', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-3'), SwapModule(name='delta-4', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-4'), SwapModule(name='delta-5', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-5'), SwapModule(name='delta-6', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-6'), SwapModule(name='delta-7', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-7'), SwapModule(name='delta-8', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-8')], chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='auto', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, seed=0, swap_space=4, gpu_memory_utilization=0.85, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=True, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=64, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=32, enable_delta=False, max_deltas=0, max_cpu_deltas=32, max_delta_bitwidth=4, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_prefetch=False, scheduler_policy='fcfs', engine_use_ray=False, disable_log_requests=True, max_log_len=None)
2024-05-12 04:30:26,922	INFO worker.py:1749 -- Started a local Ray instance.
INFO 05-12 04:30:29 llm_engine.py:87] Initializing an LLM engine (v0.3.3) with config: model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, lora_config=None, delta_config=None, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1c970>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1dd20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e5f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1eec0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f3d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e7a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ded0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d600>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1cdc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f790>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d000>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d6f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1dfc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e890>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ee30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e9b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e0e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d810>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d5d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ca60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d0f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1dba0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e470>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ed40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f190>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e680>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f7f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f220>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e320>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1da50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d4e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d420>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1db40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e410>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ece0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f940>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fdf0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ceb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f9d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e830>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1df60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d690>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2c0a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e980>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f2e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f400>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7bdfbb20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d300>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f0a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ee00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e530>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1dc60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e2c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e200>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ead0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e8f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f730>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2c520>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-12 04:40:19 selector.py:16] Using FlashAttention backend.
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1cf70>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=25546)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7fc639140f70>
[36m(RayWorkerVllm pid=25546)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=25546)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=25546)[0m     self.remove()
[36m(RayWorkerVllm pid=25546)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=25546)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=25546)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
[36m(RayWorkerVllm pid=25877)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7f178b5bcf70>
[36m(RayWorkerVllm pid=25877)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=25877)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=25877)[0m     self.remove()
[36m(RayWorkerVllm pid=25877)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=25877)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=25877)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f610>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=25546)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7fc639140f70>
[36m(RayWorkerVllm pid=25546)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=25546)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=25546)[0m     self.remove()
[36m(RayWorkerVllm pid=25546)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=25546)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=25546)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f070>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e920>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e7d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2c9a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ed70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f9a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fd90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d330>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2c340>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1cf70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d360>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fc70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1eb30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7bdfb910>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2c790>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ed70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fb50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d510>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1cf40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2cbb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ceb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f6d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f220>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e350>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e020>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2d2a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e650>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1da20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1eb00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fb20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2c820>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ff70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f400>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f2e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e230>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d990>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e290>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ec20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fa30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fc40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1c220>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ca00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1faf0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fa00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e890>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1da50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7ba2d720>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1e500>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1edd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1f490>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1fd90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7bdfbd60>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=25546)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=25546)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=25877)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=25877)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=25546)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=25546)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=25730)[0m INFO 05-12 04:49:04 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=25877)[0m INFO 05-12 04:49:13 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=25546)[0m INFO 05-12 04:49:16 selector.py:16] Using FlashAttention backend.
INFO 05-12 04:49:31 model_runner.py:155] Loading model weights took 6.1114 GB
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1d3f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa7be1ca60>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=25546)[0m INFO 05-12 04:49:32 model_runner.py:155] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=25877)[0m INFO 05-12 04:49:32 model_runner.py:155] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=25730)[0m INFO 05-12 04:49:32 model_runner.py:155] Loading model weights took 6.1114 GB
INFO 05-12 04:49:45 ray_gpu_executor.py:266] # GPU blocks: 19075, # CPU blocks: 1310
INFO 05-12 04:49:47 block_manager.py:264] disable automatic prefix caching
WARNING 05-12 04:49:48 serving_chat.py:373] No chat template provided. Chat API will not work.
INFO:     Started server process [17339]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     ::1:50982 - "GET /sysinfo HTTP/1.1" 200 OK
Translating from base-model to /vllm/.idea/full_models/Llama-2-13b-hf
Warming up starts
{'id': 56, 'prompt': 'USER: write code to generate answers to user input using ONNX\nASSISTANT:', 'timestamp': 0, 'model': 'delta-8', 'min_tokens': 327, 'max_tokens': 327}
INFO 05-12 04:49:53 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:50:19 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:50:19 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:50:24 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 27.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 04:50:29 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:50984 - "POST /v1/completions HTTP/1.1" 200 OK
Warming up ends
Issuing queries
sending 1 queries at 0.1
sending 1 queries at 0.30000000000000004
sending 1 queries at 0.4
sending 2 queries at 0.5
sending 1 queries at 0.6000000000000001
sending 1 queries at 0.7000000000000001
sending 1 queries at 1.0
sending 1 queries at 1.3
sending 1 queries at 1.4000000000000001
sending 2 queries at 1.6
sending 1 queries at 1.7000000000000002
sending 4 queries at 2.0
sending 1 queries at 2.2
sending 1 queries at 2.4000000000000004
sending 1 queries at 2.6
sending 1 queries at 3.1
sending 1 queries at 3.2
sending 1 queries at 3.3000000000000003
sending 2 queries at 3.5
sending 2 queries at 3.6
sending 1 queries at 3.9000000000000004
sending 1 queries at 4.0
sending 2 queries at 4.1000000000000005
sending 2 queries at 4.3
sending 2 queries at 4.4
sending 1 queries at 4.6000000000000005
sending 1 queries at 4.7
sending 1 queries at 4.800000000000001
sending 1 queries at 5.1000000000000005
sending 1 queries at 5.2
sending 2 queries at 5.300000000000001
sending 2 queries at 5.5
sending 1 queries at 5.6000000000000005
sending 3 queries at 5.7
sending 2 queries at 5.800000000000001
sending 1 queries at 5.9
sending 1 queries at 6.0
sending 3 queries at 6.5
sending 1 queries at 6.6000000000000005
sending 2 queries at 6.7
sending 4 queries at 6.800000000000001
sending 4 queries at 7.0
sending 2 queries at 7.2
sending 2 queries at 7.5
sending 2 queries at 7.9
sending 1 queries at 8.4
sending 1 queries at 8.5
sending 2 queries at 8.6
sending 4 queries at 8.700000000000001
sending 3 queries at 8.8
sending 1 queries at 9.0
sending 2 queries at 9.1
sending 2 queries at 9.200000000000001
sending 1 queries at 9.3
sending 2 queries at 9.600000000000001
sending 1 queries at 9.700000000000001
sending 1 queries at 9.8
sending 2 queries at 9.9
sending 1 queries at 10.0
sending 2 queries at 10.100000000000001
sending 2 queries at 10.3
sending 2 queries at 10.4
sending 1 queries at 10.600000000000001
sending 1 queries at 10.9
sending 1 queries at 11.0
sending 1 queries at 11.100000000000001
sending 1 queries at 11.200000000000001
sending 2 queries at 11.3
sending 1 queries at 11.600000000000001
sending 1 queries at 11.700000000000001
sending 1 queries at 11.9
sending 1 queries at 12.0
sending 1 queries at 12.100000000000001
sending 2 queries at 12.3
sending 1 queries at 12.5
sending 1 queries at 12.600000000000001
sending 1 queries at 12.9
sending 1 queries at 13.0
sending 2 queries at 13.200000000000001
sending 1 queries at 13.600000000000001
sending 1 queries at 13.700000000000001
sending 1 queries at 13.8
sending 3 queries at 13.9
sending 1 queries at 14.0
sending 1 queries at 14.100000000000001
sending 3 queries at 14.200000000000001
sending 1 queries at 14.3
sending 1 queries at 14.4
sending 1 queries at 14.5
sending 1 queries at 14.600000000000001
sending 1 queries at 14.700000000000001
sending 1 queries at 14.8
sending 1 queries at 14.9
sending 1 queries at 15.100000000000001
sending 2 queries at 15.200000000000001
sending 1 queries at 15.5
sending 1 queries at 15.700000000000001
sending 2 queries at 15.8
sending 1 queries at 16.1
sending 1 queries at 16.2
sending 2 queries at 17.0
sending 2 queries at 17.2
sending 2 queries at 17.400000000000002
sending 1 queries at 17.6
sending 1 queries at 17.8
sending 3 queries at 17.900000000000002
sending 1 queries at 18.0
sending 1 queries at 18.1
sending 1 queries at 18.3
sending 1 queries at 18.5
sending 1 queries at 18.900000000000002
sending 2 queries at 19.1
sending 1 queries at 19.200000000000003
sending 2 queries at 19.3
sending 4 queries at 19.400000000000002
sending 2 queries at 19.6
sending 1 queries at 19.700000000000003
sending 1 queries at 20.0
sending 3 queries at 20.1
sending 2 queries at 20.3
sending 1 queries at 20.400000000000002
sending 1 queries at 20.700000000000003
sending 1 queries at 20.8
sending 1 queries at 20.900000000000002
sending 1 queries at 21.0
sending 1 queries at 21.1
sending 3 queries at 21.200000000000003
sending 1 queries at 21.3
sending 1 queries at 21.6
sending 1 queries at 21.700000000000003
sending 2 queries at 21.8
sending 3 queries at 21.900000000000002
sending 1 queries at 22.0
sending 1 queries at 22.1
sending 4 queries at 22.200000000000003
sending 1 queries at 22.3
sending 1 queries at 22.400000000000002
sending 1 queries at 22.5
sending 1 queries at 22.700000000000003
sending 1 queries at 23.200000000000003
sending 1 queries at 23.3
sending 3 queries at 23.400000000000002
sending 2 queries at 23.6
sending 1 queries at 23.700000000000003
sending 1 queries at 23.8
sending 1 queries at 24.0
sending 1 queries at 24.1
sending 1 queries at 24.3
sending 1 queries at 24.400000000000002
sending 1 queries at 24.5
sending 1 queries at 24.6
sending 1 queries at 24.900000000000002
sending 1 queries at 25.0
sending 1 queries at 25.1
sending 1 queries at 25.400000000000002
sending 1 queries at 25.5
sending 2 queries at 25.6
sending 3 queries at 25.700000000000003
sending 2 queries at 25.8
sending 2 queries at 25.900000000000002
sending 1 queries at 26.0
sending 2 queries at 26.200000000000003
sending 2 queries at 26.3
sending 2 queries at 26.5
sending 1 queries at 26.6
sending 3 queries at 26.700000000000003
sending 1 queries at 26.8
sending 1 queries at 27.1
sending 1 queries at 27.3
sending 1 queries at 27.400000000000002
sending 2 queries at 27.700000000000003
sending 1 queries at 27.8
sending 1 queries at 27.900000000000002
sending 1 queries at 28.200000000000003
sending 4 queries at 28.3
sending 1 queries at 28.6
sending 1 queries at 28.700000000000003
sending 1 queries at 28.900000000000002
sending 2 queries at 29.0
sending 2 queries at 29.1
sending 1 queries at 29.6
sending 2 queries at 29.8
INFO 05-12 04:50:31 async_llm_engine.py:437] Reloading model to delta-5
total threads: 273
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.4 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:05 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:05 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:05 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:06 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51460 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51338 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:06 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51470 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:07 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:07 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:07 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51492 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51314 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:08 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51478 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:08 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:08 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:08 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51352 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:08 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:09 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:09 metrics.py:276] Avg prompt throughput: 289.4 tokens/s, Avg generation throughput: 354.5 tokens/s, Running: 17 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%
INFO:     ::1:51632 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51534 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:11 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51448 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51523 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:12 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51386 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51364 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51680 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:14 metrics.py:276] Avg prompt throughput: 6.6 tokens/s, Avg generation throughput: 336.0 tokens/s, Running: 8 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%
INFO:     ::1:51240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51506 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51676 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51514 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:16 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:17 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:17 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51388 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:17 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:19 metrics.py:276] Avg prompt throughput: 22.3 tokens/s, Avg generation throughput: 162.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 05-12 04:51:20 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51268 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51538 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51390 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51574 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51434 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:51124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:24 metrics.py:276] Avg prompt throughput: 6.4 tokens/s, Avg generation throughput: 176.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO:     ::1:51440 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:29 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 36.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51400 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:30 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:51:53 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:51:53 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:51:58 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:52:25 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:52:25 metrics.py:276] Avg prompt throughput: 0.7 tokens/s, Avg generation throughput: 4.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:52:30 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:52:33 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:52:35 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:52:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:52:44 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 04:53:17 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:53:17 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:53:21 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:53:26 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:53:26 metrics.py:276] Avg prompt throughput: 4.4 tokens/s, Avg generation throughput: 12.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:53:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:53:35 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 04:53:58 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:53:58 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51108 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:00 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:54:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:54:04 metrics.py:276] Avg prompt throughput: 7.5 tokens/s, Avg generation throughput: 7.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:05 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:54:09 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:54:09 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:14 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:14 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:54:18 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:54:18 metrics.py:276] Avg prompt throughput: 5.7 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51120 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:20 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 04:54:24 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:54:24 metrics.py:276] Avg prompt throughput: 3.1 tokens/s, Avg generation throughput: 6.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:54:29 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 04:54:34 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:35 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:54:39 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:54:39 metrics.py:276] Avg prompt throughput: 10.5 tokens/s, Avg generation throughput: 1.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:43 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 04:54:47 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:54:47 metrics.py:276] Avg prompt throughput: 2.9 tokens/s, Avg generation throughput: 12.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:51 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:54:55 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:54:55 metrics.py:276] Avg prompt throughput: 2.8 tokens/s, Avg generation throughput: 12.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:54:57 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 04:55:01 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:55:01 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:55:06 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:55:07 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:55:12 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:55:12 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:55:13 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:55:18 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:55:18 metrics.py:276] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 5.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:55:23 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:55:27 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:55:31 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:55:31 metrics.py:276] Avg prompt throughput: 3.7 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:55:32 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:55:36 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:55:36 metrics.py:276] Avg prompt throughput: 5.8 tokens/s, Avg generation throughput: 2.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:55:41 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 04:55:46 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:55:51 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 04:55:55 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:55:55 metrics.py:276] Avg prompt throughput: 3.7 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:56:00 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:56:00 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:56:05 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:56:05 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:56:05 metrics.py:276] Avg prompt throughput: 9.0 tokens/s, Avg generation throughput: 2.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:56:10 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:56:15 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:56:15 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:56:15 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:56:20 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:56:20 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 04:56:56 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:56:56 metrics.py:276] Avg prompt throughput: 0.7 tokens/s, Avg generation throughput: 0.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:56:56 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:57:01 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:57:01 metrics.py:276] Avg prompt throughput: 11.5 tokens/s, Avg generation throughput: 2.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:57:01 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:57:06 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:57:06 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 2.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:57:09 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 04:57:14 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:57:14 metrics.py:276] Avg prompt throughput: 5.1 tokens/s, Avg generation throughput: 12.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:57:19 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:57:20 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:57:25 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:57:25 metrics.py:276] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 5.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:57:30 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 04:57:35 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:57:39 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:57:43 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:57:43 metrics.py:276] Avg prompt throughput: 1.3 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:57:44 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:57:44 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:57:49 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:57:49 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 6.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:57:51 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:57:56 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:57:56 metrics.py:276] Avg prompt throughput: 7.7 tokens/s, Avg generation throughput: 9.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:58:01 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 04:58:06 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:58:09 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:58:13 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:58:13 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:58:18 metrics.py:276] Avg prompt throughput: 4.4 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 04:58:24 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:58:25 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:58:30 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:58:30 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 7.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:58:34 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:58:39 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:58:39 metrics.py:276] Avg prompt throughput: 1.8 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:58:40 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:58:44 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:58:44 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:58:49 metrics.py:276] Avg prompt throughput: 7.2 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51190 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:58:53 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:58:54 metrics.py:276] Avg prompt throughput: 5.8 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:58:55 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51198 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:58:56 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:58:59 metrics.py:276] Avg prompt throughput: 7.2 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:59:03 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 04:59:08 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:59:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:59:11 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:59:13 metrics.py:276] Avg prompt throughput: 21.4 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:59:18 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:59:19 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 04:59:24 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:59:24 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 7.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:59:29 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 04:59:34 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:59:35 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:59:39 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:59:41 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 04:59:46 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:59:46 metrics.py:276] Avg prompt throughput: 6.1 tokens/s, Avg generation throughput: 9.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 04:59:51 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 04:59:54 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 04:59:59 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 04:59:59 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:00:00 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:00:05 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:00:05 metrics.py:276] Avg prompt throughput: 19.4 tokens/s, Avg generation throughput: 7.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:00:10 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:00:15 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:00:16 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:00:21 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:00:21 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:00:23 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:00:28 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:00:28 metrics.py:276] Avg prompt throughput: 9.9 tokens/s, Avg generation throughput: 9.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:00:33 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:00:35 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:00:38 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:00:39 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:51224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:00:41 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:00:46 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:00:46 metrics.py:276] Avg prompt throughput: 5.5 tokens/s, Avg generation throughput: 11.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:00:51 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:00:54 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:00:58 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:00:58 metrics.py:276] Avg prompt throughput: 4.4 tokens/s, Avg generation throughput: 10.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:01:03 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51228 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:01:07 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 05:01:11 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:01:11 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:01:14 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:01:19 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:01:19 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 11.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:01:24 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:01:25 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:01:29 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:01:29 metrics.py:276] Avg prompt throughput: 4.1 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:01:34 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:01:39 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:01:41 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:01:44 metrics.py:276] Avg prompt throughput: 8.7 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:01:48 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 05:01:53 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:01:53 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:01:55 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:01:59 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:01:59 metrics.py:276] Avg prompt throughput: 4.4 tokens/s, Avg generation throughput: 9.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:02:04 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:02:06 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 05:02:33 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:02:33 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:02:38 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 28.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:02:41 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:02:46 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:02:46 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:02:51 metrics.py:276] Avg prompt throughput: 58.5 tokens/s, Avg generation throughput: 28.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:02:54 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 05:02:59 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:02:59 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51252 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:02:59 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 05:03:04 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:03:04 metrics.py:276] Avg prompt throughput: 73.5 tokens/s, Avg generation throughput: 3.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:03:09 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO:     ::1:51254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:03:12 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:03:16 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:03:16 metrics.py:276] Avg prompt throughput: 3.7 tokens/s, Avg generation throughput: 10.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:03:21 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:03:26 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:03:29 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 05:03:34 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:03:34 metrics.py:276] Avg prompt throughput: 3.9 tokens/s, Avg generation throughput: 11.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:03:35 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:03:40 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:03:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:03:43 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:03:45 metrics.py:276] Avg prompt throughput: 6.6 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:03:46 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:03:50 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:03:54 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:03:58 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:03:59 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:04:04 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51266 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:04:06 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 05:04:10 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:04:10 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:04:11 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:04:16 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:04:16 metrics.py:276] Avg prompt throughput: 6.3 tokens/s, Avg generation throughput: 6.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:04:16 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 05:04:20 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:04:21 metrics.py:276] Avg prompt throughput: 3.0 tokens/s, Avg generation throughput: 4.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51274 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:04:22 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:04:26 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51276 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:04:31 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:04:35 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:04:35 metrics.py:276] Avg prompt throughput: 2.1 tokens/s, Avg generation throughput: 14.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:04:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:04:45 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:04:50 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO:     ::1:51278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:04:51 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 05:04:56 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:04:56 metrics.py:276] Avg prompt throughput: 3.5 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:04:56 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 05:05:01 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:05:01 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:05:03 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:05:06 metrics.py:276] Avg prompt throughput: 14.2 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:05:11 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:05:14 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:05:16 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:05:21 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:05:26 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:05:27 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 05:05:31 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:05:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:05:36 metrics.py:276] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:05:41 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:05:45 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 05:05:50 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:05:50 metrics.py:276] Avg prompt throughput: 1.8 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:05:53 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 05:05:57 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:05:57 metrics.py:276] Avg prompt throughput: 2.4 tokens/s, Avg generation throughput: 11.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:06:02 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:06:05 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:06:09 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:06:09 metrics.py:276] Avg prompt throughput: 4.6 tokens/s, Avg generation throughput: 11.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:06:15 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:06:20 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:06:23 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:06:28 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:06:28 metrics.py:276] Avg prompt throughput: 1.9 tokens/s, Avg generation throughput: 13.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:06:33 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:06:33 metrics.py:276] Avg prompt throughput: 6.2 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:06:38 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 05:06:43 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:06:48 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:06:52 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:06:52 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:06:54 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 05:06:59 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:06:59 metrics.py:276] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 9.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:07:04 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:07:05 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:07:10 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:07:10 metrics.py:276] Avg prompt throughput: 8.0 tokens/s, Avg generation throughput: 6.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51304 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:07:10 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:07:15 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:07:15 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 2.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:07:20 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:07:20 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:07:25 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:07:25 metrics.py:276] Avg prompt throughput: 7.0 tokens/s, Avg generation throughput: 2.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:07:30 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 05:07:34 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:07:34 metrics.py:276] Avg prompt throughput: 5.3 tokens/s, Avg generation throughput: 15.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:07:39 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:07:43 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:07:43 metrics.py:276] Avg prompt throughput: 1.9 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51313 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:07:47 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 05:07:51 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:07:51 metrics.py:276] Avg prompt throughput: 2.3 tokens/s, Avg generation throughput: 12.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:07:55 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:07:59 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:07:59 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:08:04 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:08:04 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 05:08:09 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:08:09 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 3.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:08:14 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:08:15 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:08:20 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:08:20 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51322 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:08:24 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:08:28 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:08:28 metrics.py:276] Avg prompt throughput: 8.3 tokens/s, Avg generation throughput: 13.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51324 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:08:33 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:08:33 metrics.py:276] Avg prompt throughput: 4.4 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:08:38 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51326 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:08:40 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:08:44 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:08:44 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:08:49 metrics.py:276] Avg prompt throughput: 3.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:08:51 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 05:08:56 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:08:56 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51334 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:08:57 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 05:09:01 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:09:02 metrics.py:276] Avg prompt throughput: 7.0 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 05:09:07 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:09:11 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:09:16 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:09:16 metrics.py:276] Avg prompt throughput: 1.4 tokens/s, Avg generation throughput: 15.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51340 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:09:18 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:09:21 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51342 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:09:25 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 05:09:30 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:09:30 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51346 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:09:33 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 05:09:37 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:09:37 metrics.py:276] Avg prompt throughput: 6.3 tokens/s, Avg generation throughput: 12.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51350 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:09:41 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 05:09:45 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:09:46 metrics.py:276] Avg prompt throughput: 2.0 tokens/s, Avg generation throughput: 12.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51356 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:09:49 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:09:51 metrics.py:276] Avg prompt throughput: 42.8 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO:     ::1:51358 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:09:53 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:09:56 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51360 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:09:56 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:10:01 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO:     ::1:51362 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 05:10:03 api_server.py:156] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 05:10:06 metrics.py:276] Avg prompt throughput: 15.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
slurmstepd: error: *** JOB 3671364 ON HOST-10-140-60-6 CANCELLED AT 2024-05-12T06:23:31 ***
