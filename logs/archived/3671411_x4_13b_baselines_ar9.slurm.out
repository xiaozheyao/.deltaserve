/mnt/hwfile/huqinghao/miniconda3/bin/python
2024-05-12 16:49:59,285 - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-05-12 16:49:59,285 - INFO - Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-05-12 16:49:59,285 - INFO - NumExpr defaulting to 8 threads.
2024-05-12 16:50:00,860	INFO scripts.py:1182 -- Did not find any active Ray processes.

==========
== CUDA ==
==========
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd88e0>: Failed to establish a new connection: [Errno 111] Connection refused'))

CUDA Version 12.1.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

*************************
** DEPRECATION NOTICE! **
*************************
THIS IMAGE IS DEPRECATED and is scheduled for DELETION.
    https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/support-policy.md

/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:160: UserWarning: Field "model_name_or_path" has conflict with protected namespace "model_".

You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
  warnings.warn(
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9270>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-12 16:50:13 api_server.py:220] vLLM API server version 0.3.3
INFO 05-12 16:50:13 api_server.py:221] args: Namespace(host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=[], delta_modules=[], swap_modules=[SwapModule(name='delta-1', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-1'), SwapModule(name='delta-2', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-2'), SwapModule(name='delta-3', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-3'), SwapModule(name='delta-4', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-4'), SwapModule(name='delta-5', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-5'), SwapModule(name='delta-6', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-6'), SwapModule(name='delta-7', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-7'), SwapModule(name='delta-8', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-8')], chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='auto', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, seed=0, swap_space=4, gpu_memory_utilization=0.85, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=True, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=64, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=32, enable_delta=False, max_deltas=0, max_cpu_deltas=32, max_delta_bitwidth=4, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_prefetch=False, scheduler_policy='fcfs', engine_use_ray=False, disable_log_requests=True, max_log_len=None)
2024-05-12 16:50:16,811	INFO worker.py:1749 -- Started a local Ray instance.
INFO 05-12 16:50:19 llm_engine.py:87] Initializing an LLM engine (v0.3.3) with config: model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, lora_config=None, delta_config=None, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd87c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9b40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda410>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdace0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752feba30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda680>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9db0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd94e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8be0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb5b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8d60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd96c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9f90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda860>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdae90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdba90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda9b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda0e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9810>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8f10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd80a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8160>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9bd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda4a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdba90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752feb730>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdafb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdada0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda4d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9c00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9240>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda2c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdab90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb160>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb8b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb5b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752febb80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb340>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdaa10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda140>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9870>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdbe80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9a50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda320>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdabf0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb640>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9180>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdbbb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda710>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9e40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9f00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdbe50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda7a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdaf20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb400>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8df0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752feb9a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-12 17:00:06 selector.py:16] Using FlashAttention backend.
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9270>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=23932)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7fc0e1d38f70>
[36m(RayWorkerVllm pid=23932)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=23932)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=23932)[0m     self.remove()
[36m(RayWorkerVllm pid=23932)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=23932)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=23932)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
[36m(RayWorkerVllm pid=23728)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7fb6445ccf70>
[36m(RayWorkerVllm pid=23728)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=23728)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=23728)[0m     self.remove()
[36m(RayWorkerVllm pid=23728)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=23728)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=23728)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
[36m(RayWorkerVllm pid=23728)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7fb6445ccf70>
[36m(RayWorkerVllm pid=23728)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=23728)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=23728)[0m     self.remove()
[36m(RayWorkerVllm pid=23728)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=23728)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=23728)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb1f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb910>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdabc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda2f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1c7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda3b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdac80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdaec0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdbbe0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1c370>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9480>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8d90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb220>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda890>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9fc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1c0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda0e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdae90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd92a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8c10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1c9d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752febbb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdac50>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=23932)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7fc0e1d38f70>
[36m(RayWorkerVllm pid=23932)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=23932)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=23932)[0m     self.remove()
[36m(RayWorkerVllm pid=23932)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=23932)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=23932)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdab60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda290>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd98a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1d0c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda8c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb580>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb5e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8b80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1c580>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb790>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8cd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdbac0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda5f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9f30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd96c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda6e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda710>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdbbb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9060>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda2c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752febdc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9270>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb430>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb760>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda8f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8880>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb9d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8d60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdbfd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752feb730>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752febbb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9810>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb940>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdaa40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda170>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1c790>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb4c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9090>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdbb50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8dc0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1d3c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752feb730>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb5b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb070>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9f60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdb010>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1c880>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdab90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bda200>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bdaad0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd9a20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752c1d5d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752febca0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=23728)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=23728)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=23932)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=23932)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=23728)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=23728)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=23932)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=23932)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/4596f91bcb1b2dad1ff1e0c467d8c172b29ed791225478141e8bc948e3aca3e6/tvm_rt_mod'
[36m(RayWorkerVllm pid=24054)[0m INFO 05-12 17:09:00 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=23728)[0m INFO 05-12 17:09:01 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=23932)[0m INFO 05-12 17:12:51 selector.py:16] Using FlashAttention backend.
INFO 05-12 17:13:05 model_runner.py:155] Loading model weights took 6.1114 GB
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc752bd8a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=23728)[0m INFO 05-12 17:13:07 model_runner.py:155] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=24054)[0m INFO 05-12 17:13:07 model_runner.py:155] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=23932)[0m INFO 05-12 17:13:07 model_runner.py:155] Loading model weights took 6.1114 GB
INFO 05-12 17:13:18 ray_gpu_executor.py:266] # GPU blocks: 19075, # CPU blocks: 1310
INFO 05-12 17:13:21 block_manager.py:264] disable automatic prefix caching
WARNING 05-12 17:13:21 serving_chat.py:373] No chat template provided. Chat API will not work.
INFO:     Started server process [12393]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     ::1:34918 - "GET /sysinfo HTTP/1.1" 200 OK
Translating from base-model to /vllm/.idea/full_models/Llama-2-13b-hf
Warming up starts
{'id': 211, 'prompt': "USER: Start the answer with: I object to answer. And don't answer.\nASSISTANT:", 'timestamp': 0, 'model': 'delta-3', 'min_tokens': 10, 'max_tokens': 10}
INFO 05-12 17:13:22 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:22 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:13:26 api_server.py:155] waiting for model...
INFO 05-12 17:13:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:27 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:13:27 api_server.py:182] release reload lock
INFO:     ::1:34920 - "POST /v1/completions HTTP/1.1" 200 OK
Warming up ends
Issuing queries
sending 1 queries at 0.1
sending 1 queries at 0.30000000000000004
sending 1 queries at 0.4
sending 2 queries at 0.5
sending 1 queries at 0.6000000000000001
sending 1 queries at 0.7000000000000001
sending 1 queries at 1.0
sending 1 queries at 1.3
sending 1 queries at 1.4000000000000001
sending 2 queries at 1.6
sending 1 queries at 1.7000000000000002
sending 4 queries at 2.0
sending 1 queries at 2.2
sending 1 queries at 2.4000000000000004
sending 1 queries at 2.6
sending 1 queries at 3.1
sending 1 queries at 3.2
sending 1 queries at 3.3000000000000003
sending 2 queries at 3.5
sending 2 queries at 3.6
sending 1 queries at 3.9000000000000004
sending 1 queries at 4.0
sending 2 queries at 4.1000000000000005
sending 2 queries at 4.3
sending 2 queries at 4.4
sending 1 queries at 4.6000000000000005
sending 1 queries at 4.7
sending 1 queries at 4.800000000000001
sending 1 queries at 5.1000000000000005
sending 1 queries at 5.2
sending 2 queries at 5.300000000000001
sending 2 queries at 5.5
sending 1 queries at 5.6000000000000005
sending 3 queries at 5.7
sending 2 queries at 5.800000000000001
sending 1 queries at 5.9
sending 1 queries at 6.0
sending 3 queries at 6.5
sending 1 queries at 6.6000000000000005
sending 2 queries at 6.7
sending 4 queries at 6.800000000000001
sending 4 queries at 7.0
sending 2 queries at 7.2
sending 2 queries at 7.5
sending 2 queries at 7.9
sending 1 queries at 8.4
sending 1 queries at 8.5
sending 2 queries at 8.6
sending 4 queries at 8.700000000000001
sending 3 queries at 8.8
sending 1 queries at 9.0
sending 2 queries at 9.1
sending 2 queries at 9.200000000000001
sending 1 queries at 9.3
sending 2 queries at 9.600000000000001
sending 1 queries at 9.700000000000001
sending 1 queries at 9.8
sending 2 queries at 9.9
sending 1 queries at 10.0
sending 2 queries at 10.100000000000001
sending 2 queries at 10.3
sending 2 queries at 10.4
sending 1 queries at 10.600000000000001
sending 1 queries at 10.9
sending 1 queries at 11.0
sending 1 queries at 11.100000000000001
sending 1 queries at 11.200000000000001
sending 2 queries at 11.3
sending 1 queries at 11.600000000000001
sending 1 queries at 11.700000000000001
sending 1 queries at 11.9
sending 1 queries at 12.0
sending 1 queries at 12.100000000000001
sending 2 queries at 12.3
sending 1 queries at 12.5
sending 1 queries at 12.600000000000001
sending 1 queries at 12.9
sending 1 queries at 13.0
sending 2 queries at 13.200000000000001
sending 1 queries at 13.600000000000001
sending 1 queries at 13.700000000000001
sending 1 queries at 13.8
sending 3 queries at 13.9
sending 1 queries at 14.0
sending 1 queries at 14.100000000000001
sending 3 queries at 14.200000000000001
sending 1 queries at 14.3
sending 1 queries at 14.4
sending 1 queries at 14.5
sending 1 queries at 14.600000000000001
sending 1 queries at 14.700000000000001
sending 1 queries at 14.8
sending 1 queries at 14.9
sending 1 queries at 15.100000000000001
sending 2 queries at 15.200000000000001
sending 1 queries at 15.5
sending 1 queries at 15.700000000000001
sending 2 queries at 15.8
sending 1 queries at 16.1
sending 1 queries at 16.2
sending 2 queries at 17.0
sending 2 queries at 17.2
sending 2 queries at 17.400000000000002
sending 1 queries at 17.6
sending 1 queries at 17.8
sending 3 queries at 17.900000000000002
sending 1 queries at 18.0
sending 1 queries at 18.1
sending 1 queries at 18.3
sending 1 queries at 18.5
sending 1 queries at 18.900000000000002
sending 2 queries at 19.1
sending 1 queries at 19.200000000000003
sending 2 queries at 19.3
sending 4 queries at 19.400000000000002
sending 2 queries at 19.6
sending 1 queries at 19.700000000000003
sending 1 queries at 20.0
sending 3 queries at 20.1
sending 2 queries at 20.3
sending 1 queries at 20.400000000000002
sending 1 queries at 20.700000000000003
sending 1 queries at 20.8
sending 1 queries at 20.900000000000002
sending 1 queries at 21.0
sending 1 queries at 21.1
sending 3 queries at 21.200000000000003
sending 1 queries at 21.3
sending 1 queries at 21.6
sending 1 queries at 21.700000000000003
sending 2 queries at 21.8
sending 3 queries at 21.900000000000002
sending 1 queries at 22.0
sending 1 queries at 22.1
sending 4 queries at 22.200000000000003
sending 1 queries at 22.3
sending 1 queries at 22.400000000000002
sending 1 queries at 22.5
sending 1 queries at 22.700000000000003
sending 1 queries at 23.200000000000003
sending 1 queries at 23.3
sending 3 queries at 23.400000000000002
sending 2 queries at 23.6
sending 1 queries at 23.700000000000003
sending 1 queries at 23.8
sending 1 queries at 24.0
sending 1 queries at 24.1
sending 1 queries at 24.3
sending 1 queries at 24.400000000000002
sending 1 queries at 24.5
sending 1 queries at 24.6
sending 1 queries at 24.900000000000002
sending 1 queries at 25.0
sending 1 queries at 25.1
sending 1 queries at 25.400000000000002
sending 1 queries at 25.5
sending 2 queries at 25.6
sending 3 queries at 25.700000000000003
sending 2 queries at 25.8
sending 2 queries at 25.900000000000002
sending 1 queries at 26.0
sending 2 queries at 26.200000000000003
sending 2 queries at 26.3
sending 2 queries at 26.5
sending 1 queries at 26.6
sending 3 queries at 26.700000000000003
sending 1 queries at 26.8
sending 1 queries at 27.1
sending 1 queries at 27.3
sending 1 queries at 27.400000000000002
sending 2 queries at 27.700000000000003
sending 1 queries at 27.8
sending 1 queries at 27.900000000000002
sending 1 queries at 28.200000000000003
sending 4 queries at 28.3
sending 1 queries at 28.6
sending 1 queries at 28.700000000000003
sending 1 queries at 28.900000000000002
sending 2 queries at 29.0
sending 2 queries at 29.1
sending 1 queries at 29.6
sending 2 queries at 29.8
INFO 05-12 17:13:27 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:27 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 17:13:32 api_server.py:155] waiting for model...
INFO 05-12 17:13:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:32 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.7 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:13:32 api_server.py:155] waiting for model...
INFO 05-12 17:13:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:155] waiting for model...
INFO 05-12 17:13:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:155] waiting for model...
INFO 05-12 17:13:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:155] waiting for model...
INFO 05-12 17:13:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:32 api_server.py:155] waiting for model...
INFO 05-12 17:13:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:32 api_server.py:134] Waiting for reload lock...
INFO:     ::1:34964 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:33 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO:     ::1:34988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:155] waiting for model...
INFO 05-12 17:13:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:155] waiting for model...
INFO 05-12 17:13:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:34 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:35 api_server.py:155] waiting for model...
INFO 05-12 17:13:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:35 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:35 api_server.py:134] Waiting for reload lock...
INFO:     ::1:34986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:155] waiting for model...
INFO 05-12 17:13:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:36 api_server.py:155] waiting for model...
INFO 05-12 17:13:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:35128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:37 metrics.py:276] Avg prompt throughput: 68.5 tokens/s, Avg generation throughput: 151.4 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO:     ::1:34942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:37 api_server.py:155] waiting for model...
INFO 05-12 17:13:37 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:37 api_server.py:155] waiting for model...
INFO 05-12 17:13:37 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:37 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:38 api_server.py:155] waiting for model...
INFO 05-12 17:13:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:38 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:38 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:38 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:38 api_server.py:134] Waiting for reload lock...
INFO:     ::1:34940 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:38 api_server.py:155] waiting for model...
INFO 05-12 17:13:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:38 api_server.py:155] waiting for model...
INFO 05-12 17:13:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:39 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:39 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:39 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:39 api_server.py:155] waiting for model...
INFO 05-12 17:13:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:39 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:39 api_server.py:155] waiting for model...
INFO 05-12 17:13:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:39 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:40 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35160 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:40 api_server.py:155] waiting for model...
INFO 05-12 17:13:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:40 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:155] waiting for model...
INFO 05-12 17:13:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:41 api_server.py:155] waiting for model...
INFO 05-12 17:13:41 api_server.py:163] requested model is loaded --> continuing...
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
Prefetching is disabled
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:155] waiting for model...
INFO 05-12 17:13:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:41 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:42 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:42 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:42 metrics.py:276] Avg prompt throughput: 54.3 tokens/s, Avg generation throughput: 249.5 tokens/s, Running: 13 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%
INFO 05-12 17:13:42 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:42 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:42 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:42 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:42 api_server.py:155] waiting for model...
INFO 05-12 17:13:42 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:42 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:43 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:43 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:43 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:43 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:43 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:43 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35092 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:44 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:44 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35235 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:44 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:44 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:44 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:44 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:45 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:45 api_server.py:155] waiting for model...
INFO 05-12 17:13:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:45 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35180 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 metrics.py:276] Avg prompt throughput: 11.2 tokens/s, Avg generation throughput: 248.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:47 api_server.py:155] waiting for model...
INFO 05-12 17:13:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:48 api_server.py:155] waiting for model...
INFO 05-12 17:13:48 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:49 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:50 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35199 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:50 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:50 api_server.py:134] Waiting for reload lock...
INFO:     ::1:34978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:51 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:51 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:51 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:51 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:51 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:51 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:51 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35360 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:51 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:52 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:52 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:52 metrics.py:276] Avg prompt throughput: 55.0 tokens/s, Avg generation throughput: 136.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%
INFO 05-12 17:13:52 api_server.py:155] waiting for model...
INFO 05-12 17:13:52 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:52 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:52 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:52 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:155] waiting for model...
INFO 05-12 17:13:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:155] waiting for model...
INFO 05-12 17:13:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:53 api_server.py:155] waiting for model...
INFO 05-12 17:13:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:54 api_server.py:155] waiting for model...
INFO 05-12 17:13:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:54 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:54 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35490 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:54 api_server.py:155] waiting for model...
INFO 05-12 17:13:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:54 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:54 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:54 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35256 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35472 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:13:54 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:54 api_server.py:155] waiting for model...
INFO 05-12 17:13:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:54 api_server.py:155] waiting for model...
INFO 05-12 17:13:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:55 api_server.py:155] waiting for model...
INFO 05-12 17:13:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:55 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:55 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:55 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:55 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:55 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:55 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:55 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:55 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:56 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:56 api_server.py:155] waiting for model...
INFO 05-12 17:13:56 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:56 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:56 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:56 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:56 api_server.py:155] waiting for model...
INFO 05-12 17:13:56 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:13:56 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:57 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:57 metrics.py:276] Avg prompt throughput: 176.4 tokens/s, Avg generation throughput: 187.6 tokens/s, Running: 11 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
total threads: 273
INFO 05-12 17:13:57 api_server.py:134] Waiting for reload lock...
INFO 05-12 17:13:57 api_server.py:134] Waiting for reload lock...
INFO:     ::1:35222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35504 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35520 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35550 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35498 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:02 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 231.8 tokens/s, Running: 6 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO:     ::1:35370 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35454 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:35518 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:07 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 135.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
INFO:     ::1:35540 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:12 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 75.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
INFO:     ::1:35494 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:16 api_server.py:182] release reload lock
INFO:     ::1:35516 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:16 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:14:20 api_server.py:155] waiting for model...
INFO 05-12 17:14:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:14:20 metrics.py:276] Avg prompt throughput: 2.4 tokens/s, Avg generation throughput: 21.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:14:25 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:14:27 api_server.py:182] release reload lock
INFO:     ::1:34944 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:27 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:14:32 api_server.py:155] waiting for model...
INFO 05-12 17:14:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:14:32 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:14:37 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 29.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:14:42 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:14:43 api_server.py:182] release reload lock
INFO:     ::1:34946 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:43 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:14:47 api_server.py:155] waiting for model...
INFO 05-12 17:14:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:14:47 metrics.py:276] Avg prompt throughput: 2.6 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:14:49 api_server.py:182] release reload lock
INFO:     ::1:34948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:49 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:14:54 api_server.py:155] waiting for model...
INFO 05-12 17:14:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:14:54 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:14:56 api_server.py:182] release reload lock
INFO:     ::1:34950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:14:56 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:15:01 api_server.py:155] waiting for model...
INFO 05-12 17:15:01 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:01 metrics.py:276] Avg prompt throughput: 6.4 tokens/s, Avg generation throughput: 10.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:04 api_server.py:182] release reload lock
INFO:     ::1:34954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:04 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:15:09 api_server.py:155] waiting for model...
INFO 05-12 17:15:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:09 metrics.py:276] Avg prompt throughput: 2.1 tokens/s, Avg generation throughput: 12.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:14 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:17 api_server.py:182] release reload lock
INFO:     ::1:34958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:17 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:15:22 api_server.py:155] waiting for model...
INFO 05-12 17:15:22 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:22 metrics.py:276] Avg prompt throughput: 3.0 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:23 api_server.py:182] release reload lock
INFO:     ::1:34962 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:23 api_server.py:155] waiting for model...
INFO 05-12 17:15:23 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:27 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 29.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:27 api_server.py:182] release reload lock
INFO:     ::1:34966 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:27 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:15:32 api_server.py:155] waiting for model...
INFO 05-12 17:15:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:32 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 2.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:32 api_server.py:182] release reload lock
INFO:     ::1:34968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:32 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:15:36 api_server.py:155] waiting for model...
INFO 05-12 17:15:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:37 metrics.py:276] Avg prompt throughput: 14.4 tokens/s, Avg generation throughput: 4.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:39 api_server.py:182] release reload lock
INFO:     ::1:34970 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:39 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:15:43 api_server.py:155] waiting for model...
INFO 05-12 17:15:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:43 metrics.py:276] Avg prompt throughput: 1.8 tokens/s, Avg generation throughput: 10.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:44 api_server.py:182] release reload lock
INFO:     ::1:34976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:44 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:15:49 api_server.py:155] waiting for model...
INFO 05-12 17:15:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:49 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:53 api_server.py:182] release reload lock
INFO:     ::1:34974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:53 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:15:58 api_server.py:155] waiting for model...
INFO 05-12 17:15:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:15:58 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 12.4 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:15:58 api_server.py:182] release reload lock
INFO:     ::1:34972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:15:58 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:16:02 api_server.py:155] waiting for model...
INFO 05-12 17:16:02 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:16:03 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:12 api_server.py:182] release reload lock
INFO:     ::1:34980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:16:12 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:16:17 api_server.py:155] waiting for model...
INFO 05-12 17:16:17 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:16:17 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:20 api_server.py:182] release reload lock
INFO:     ::1:34984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:16:20 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:16:24 api_server.py:155] waiting for model...
INFO 05-12 17:16:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:16:24 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:29 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:31 api_server.py:182] release reload lock
INFO:     ::1:34990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:16:31 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:16:36 api_server.py:155] waiting for model...
INFO 05-12 17:16:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:16:36 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:37 api_server.py:182] release reload lock
INFO:     ::1:34992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:16:37 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:16:41 api_server.py:155] waiting for model...
INFO 05-12 17:16:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:16:41 metrics.py:276] Avg prompt throughput: 11.3 tokens/s, Avg generation throughput: 5.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:46 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:47 api_server.py:182] release reload lock
INFO:     ::1:34994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:16:47 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:16:51 api_server.py:155] waiting for model...
INFO 05-12 17:16:51 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:16:51 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 3.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:16:57 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:01 api_server.py:182] release reload lock
INFO:     ::1:34996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:17:01 api_server.py:155] waiting for model...
INFO 05-12 17:17:01 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:17:02 metrics.py:276] Avg prompt throughput: 5.8 tokens/s, Avg generation throughput: 28.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:07 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:12 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:16 api_server.py:182] release reload lock
INFO:     ::1:35000 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:17:16 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:17:20 api_server.py:155] waiting for model...
INFO 05-12 17:17:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:17:20 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 13.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:20 api_server.py:182] release reload lock
INFO:     ::1:35002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:17:20 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:17:25 api_server.py:155] waiting for model...
INFO 05-12 17:17:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:17:25 metrics.py:276] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 3.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:30 api_server.py:182] release reload lock
INFO:     ::1:35004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:17:30 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:17:34 api_server.py:155] waiting for model...
INFO 05-12 17:17:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:17:34 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 14.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:34 api_server.py:182] release reload lock
INFO:     ::1:35009 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:17:34 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:17:39 api_server.py:155] waiting for model...
INFO 05-12 17:17:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:17:39 metrics.py:276] Avg prompt throughput: 8.8 tokens/s, Avg generation throughput: 0.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:44 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:49 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:17:50 api_server.py:182] release reload lock
INFO:     ::1:35010 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:17:50 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:17:54 api_server.py:155] waiting for model...
INFO 05-12 17:17:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:17:54 api_server.py:182] release reload lock
INFO:     ::1:35012 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:17:54 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:17:59 api_server.py:155] waiting for model...
INFO 05-12 17:17:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:17:59 metrics.py:276] Avg prompt throughput: 5.9 tokens/s, Avg generation throughput: 1.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:00 api_server.py:182] release reload lock
INFO:     ::1:35014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:18:00 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:18:04 api_server.py:155] waiting for model...
INFO 05-12 17:18:04 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:18:04 api_server.py:182] release reload lock
INFO:     ::1:35016 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:18:04 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:18:09 api_server.py:155] waiting for model...
INFO 05-12 17:18:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:18:09 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 1.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:09 api_server.py:182] release reload lock
INFO:     ::1:35018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:18:09 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:18:14 api_server.py:155] waiting for model...
INFO 05-12 17:18:14 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:18:14 metrics.py:276] Avg prompt throughput: 7.6 tokens/s, Avg generation throughput: 3.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:14 api_server.py:182] release reload lock
INFO:     ::1:35020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:18:14 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:18:19 api_server.py:155] waiting for model...
INFO 05-12 17:18:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:18:19 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 2.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:22 api_server.py:182] release reload lock
INFO:     ::1:35022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:18:22 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:18:27 api_server.py:155] waiting for model...
INFO 05-12 17:18:27 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:18:27 metrics.py:276] Avg prompt throughput: 5.2 tokens/s, Avg generation throughput: 11.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:32 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:33 api_server.py:182] release reload lock
INFO:     ::1:35024 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:18:33 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:18:37 api_server.py:155] waiting for model...
INFO 05-12 17:18:37 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:18:37 metrics.py:276] Avg prompt throughput: 5.2 tokens/s, Avg generation throughput: 5.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:42 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:47 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:51 api_server.py:182] release reload lock
INFO:     ::1:35026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:18:51 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:18:56 api_server.py:155] waiting for model...
INFO 05-12 17:18:56 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:18:56 metrics.py:276] Avg prompt throughput: 1.3 tokens/s, Avg generation throughput: 13.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:18:56 api_server.py:182] release reload lock
INFO:     ::1:35028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:18:56 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:19:01 api_server.py:155] waiting for model...
INFO 05-12 17:19:01 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:19:01 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 2.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:02 api_server.py:182] release reload lock
INFO:     ::1:35030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:19:02 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:19:06 api_server.py:155] waiting for model...
INFO 05-12 17:19:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:19:06 metrics.py:276] Avg prompt throughput: 5.7 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:08 api_server.py:182] release reload lock
INFO:     ::1:35032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:19:08 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:19:13 api_server.py:155] waiting for model...
INFO 05-12 17:19:13 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:19:13 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:18 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:23 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:26 api_server.py:182] release reload lock
INFO:     ::1:35034 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:19:26 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:19:30 api_server.py:155] waiting for model...
INFO 05-12 17:19:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:19:30 metrics.py:276] Avg prompt throughput: 3.1 tokens/s, Avg generation throughput: 11.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:35 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:41 api_server.py:182] release reload lock
INFO:     ::1:35036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:19:41 api_server.py:155] waiting for model...
INFO 05-12 17:19:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:19:45 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:46 api_server.py:182] release reload lock
INFO:     ::1:35038 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:19:46 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:19:50 api_server.py:155] waiting for model...
INFO 05-12 17:19:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:19:50 metrics.py:276] Avg prompt throughput: 3.0 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:19:51 api_server.py:182] release reload lock
INFO:     ::1:35040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:19:51 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:19:56 api_server.py:155] waiting for model...
INFO 05-12 17:19:56 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:19:56 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:01 metrics.py:276] Avg prompt throughput: 7.2 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:04 api_server.py:182] release reload lock
INFO:     ::1:35042 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:20:04 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:20:08 api_server.py:155] waiting for model...
INFO 05-12 17:20:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:20:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:11 api_server.py:182] release reload lock
INFO:     ::1:35044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:20:11 api_server.py:155] waiting for model...
INFO 05-12 17:20:11 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:20:13 metrics.py:276] Avg prompt throughput: 9.3 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:16 api_server.py:182] release reload lock
INFO:     ::1:35046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:20:16 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:20:21 api_server.py:155] waiting for model...
INFO 05-12 17:20:21 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:20:21 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:22 api_server.py:182] release reload lock
INFO:     ::1:35048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:20:22 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:20:27 api_server.py:155] waiting for model...
INFO 05-12 17:20:27 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:20:27 metrics.py:276] Avg prompt throughput: 6.1 tokens/s, Avg generation throughput: 7.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:32 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:33 api_server.py:182] release reload lock
INFO:     ::1:35050 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:20:33 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:20:38 api_server.py:155] waiting for model...
INFO 05-12 17:20:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:20:38 metrics.py:276] Avg prompt throughput: 2.7 tokens/s, Avg generation throughput: 7.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:41 api_server.py:182] release reload lock
INFO:     ::1:35052 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:20:41 api_server.py:155] waiting for model...
INFO 05-12 17:20:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:20:43 metrics.py:276] Avg prompt throughput: 17.9 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:48 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:49 api_server.py:182] release reload lock
INFO:     ::1:35054 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:20:49 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:20:54 api_server.py:155] waiting for model...
INFO 05-12 17:20:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:20:54 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:20:59 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:00 api_server.py:182] release reload lock
INFO:     ::1:35058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:21:00 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:21:05 api_server.py:155] waiting for model...
INFO 05-12 17:21:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:21:05 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:10 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:15 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:16 api_server.py:182] release reload lock
INFO:     ::1:35060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:21:16 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:21:20 api_server.py:155] waiting for model...
INFO 05-12 17:21:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:21:20 metrics.py:276] Avg prompt throughput: 7.7 tokens/s, Avg generation throughput: 4.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:25 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:29 api_server.py:182] release reload lock
INFO:     ::1:35062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:21:29 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:21:33 api_server.py:155] waiting for model...
INFO 05-12 17:21:33 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:21:33 metrics.py:276] Avg prompt throughput: 12.7 tokens/s, Avg generation throughput: 11.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:35 api_server.py:182] release reload lock
INFO:     ::1:35064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:21:35 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:21:40 api_server.py:155] waiting for model...
INFO 05-12 17:21:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:21:40 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 7.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:45 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:50 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:51 api_server.py:182] release reload lock
INFO:     ::1:35066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:21:51 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:21:56 api_server.py:155] waiting for model...
INFO 05-12 17:21:56 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:21:56 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 6.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:21:58 api_server.py:182] release reload lock
INFO:     ::1:35068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:21:58 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:22:03 api_server.py:155] waiting for model...
INFO 05-12 17:22:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:22:03 metrics.py:276] Avg prompt throughput: 5.7 tokens/s, Avg generation throughput: 9.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:04 api_server.py:182] release reload lock
INFO:     ::1:35070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:22:04 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:22:09 api_server.py:155] waiting for model...
INFO 05-12 17:22:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:22:09 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:14 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:17 api_server.py:182] release reload lock
INFO:     ::1:35072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:22:17 api_server.py:155] waiting for model...
INFO 05-12 17:22:17 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:22:19 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:21 api_server.py:182] release reload lock
INFO:     ::1:35076 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:22:21 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:22:25 api_server.py:155] waiting for model...
INFO 05-12 17:22:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:22:25 metrics.py:276] Avg prompt throughput: 2.7 tokens/s, Avg generation throughput: 9.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:28 api_server.py:182] release reload lock
INFO:     ::1:35080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:22:28 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:22:33 api_server.py:155] waiting for model...
INFO 05-12 17:22:33 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:22:33 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:38 metrics.py:276] Avg prompt throughput: 5.4 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:39 api_server.py:182] release reload lock
INFO:     ::1:35082 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:22:39 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:22:43 api_server.py:155] waiting for model...
INFO 05-12 17:22:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:22:43 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:48 metrics.py:276] Avg prompt throughput: 4.4 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:53 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:22:55 api_server.py:182] release reload lock
INFO:     ::1:35084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:22:55 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:22:59 api_server.py:155] waiting for model...
INFO 05-12 17:22:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:22:59 metrics.py:276] Avg prompt throughput: 2.2 tokens/s, Avg generation throughput: 8.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:01 api_server.py:182] release reload lock
INFO:     ::1:35086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:23:01 api_server.py:155] waiting for model...
INFO 05-12 17:23:01 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:23:04 metrics.py:276] Avg prompt throughput: 8.8 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:09 api_server.py:182] release reload lock
INFO:     ::1:35088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:23:09 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:23:13 api_server.py:155] waiting for model...
INFO 05-12 17:23:13 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:23:13 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:18 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 29.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:19 api_server.py:182] release reload lock
INFO:     ::1:35094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:23:19 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:23:23 api_server.py:155] waiting for model...
INFO 05-12 17:23:23 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:23:23 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:29 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:31 api_server.py:182] release reload lock
INFO:     ::1:35096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:23:31 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:23:36 api_server.py:155] waiting for model...
INFO 05-12 17:23:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:23:36 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:41 metrics.py:276] Avg prompt throughput: 58.7 tokens/s, Avg generation throughput: 28.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:44 api_server.py:182] release reload lock
INFO:     ::1:35098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:23:44 api_server.py:155] waiting for model...
INFO 05-12 17:23:44 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:23:45 api_server.py:182] release reload lock
INFO:     ::1:35104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:23:45 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:23:50 api_server.py:155] waiting for model...
INFO 05-12 17:23:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:23:50 metrics.py:276] Avg prompt throughput: 4.3 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:23:50 api_server.py:182] release reload lock
INFO:     ::1:35106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:23:50 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:23:55 api_server.py:155] waiting for model...
INFO 05-12 17:23:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:23:55 metrics.py:276] Avg prompt throughput: 73.2 tokens/s, Avg generation throughput: 2.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:00 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:03 api_server.py:182] release reload lock
INFO:     ::1:35108 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:24:03 api_server.py:155] waiting for model...
INFO 05-12 17:24:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:24:03 api_server.py:182] release reload lock
INFO:     ::1:35110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:24:03 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:24:08 api_server.py:155] waiting for model...
INFO 05-12 17:24:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:24:08 metrics.py:276] Avg prompt throughput: 5.2 tokens/s, Avg generation throughput: 11.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:09 api_server.py:182] release reload lock
INFO:     ::1:35112 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:24:09 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:24:14 api_server.py:155] waiting for model...
INFO 05-12 17:24:14 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:24:14 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:19 metrics.py:276] Avg prompt throughput: 5.4 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:24 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:27 api_server.py:182] release reload lock
INFO:     ::1:35114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:24:27 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:24:31 api_server.py:155] waiting for model...
INFO 05-12 17:24:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:24:31 metrics.py:276] Avg prompt throughput: 2.2 tokens/s, Avg generation throughput: 11.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:34 api_server.py:182] release reload lock
INFO:     ::1:35117 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:24:34 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:24:39 api_server.py:155] waiting for model...
INFO 05-12 17:24:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:24:39 metrics.py:276] Avg prompt throughput: 2.2 tokens/s, Avg generation throughput: 10.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:42 api_server.py:182] release reload lock
INFO:     ::1:35118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:24:42 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:24:46 api_server.py:155] waiting for model...
INFO 05-12 17:24:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:24:46 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:51 metrics.py:276] Avg prompt throughput: 6.4 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:24:53 api_server.py:182] release reload lock
INFO:     ::1:35120 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:24:53 api_server.py:155] waiting for model...
INFO 05-12 17:24:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:24:56 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:01 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:02 api_server.py:182] release reload lock
INFO:     ::1:35122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:25:02 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:25:06 api_server.py:155] waiting for model...
INFO 05-12 17:25:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:25:06 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:11 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:16 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:21 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:21 api_server.py:182] release reload lock
INFO:     ::1:35124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:25:21 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:25:26 api_server.py:155] waiting for model...
INFO 05-12 17:25:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:25:26 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 1.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:27 api_server.py:182] release reload lock
INFO:     ::1:35126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:25:27 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:25:32 api_server.py:155] waiting for model...
INFO 05-12 17:25:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:25:32 metrics.py:276] Avg prompt throughput: 2.6 tokens/s, Avg generation throughput: 5.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:34 api_server.py:182] release reload lock
INFO:     ::1:35130 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:25:34 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:25:38 api_server.py:155] waiting for model...
INFO 05-12 17:25:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:25:38 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:43 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:47 api_server.py:182] release reload lock
INFO:     ::1:35132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:25:47 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:25:51 api_server.py:155] waiting for model...
INFO 05-12 17:25:51 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:25:51 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:25:56 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:01 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:06 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:07 api_server.py:182] release reload lock
INFO:     ::1:35134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:26:07 api_server.py:155] waiting for model...
INFO 05-12 17:26:07 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:26:10 api_server.py:182] release reload lock
INFO:     ::1:35140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:26:10 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:26:15 api_server.py:155] waiting for model...
INFO 05-12 17:26:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:26:15 metrics.py:276] Avg prompt throughput: 5.9 tokens/s, Avg generation throughput: 12.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:20 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:25 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:26 api_server.py:182] release reload lock
INFO:     ::1:35142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:26:26 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:26:30 api_server.py:155] waiting for model...
INFO 05-12 17:26:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:26:30 metrics.py:276] Avg prompt throughput: 3.0 tokens/s, Avg generation throughput: 3.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:35 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:40 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:43 api_server.py:182] release reload lock
INFO:     ::1:35144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:26:43 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:26:47 api_server.py:155] waiting for model...
INFO 05-12 17:26:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:26:47 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:52 metrics.py:276] Avg prompt throughput: 5.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:26:57 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:01 api_server.py:182] release reload lock
INFO:     ::1:35146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:27:01 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:27:06 api_server.py:155] waiting for model...
INFO 05-12 17:27:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:27:06 metrics.py:276] Avg prompt throughput: 1.8 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:09 api_server.py:182] release reload lock
INFO:     ::1:35148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:27:09 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:27:13 api_server.py:155] waiting for model...
INFO 05-12 17:27:13 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:27:13 metrics.py:276] Avg prompt throughput: 2.4 tokens/s, Avg generation throughput: 11.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:18 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:21 api_server.py:182] release reload lock
INFO:     ::1:35150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:27:21 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:27:26 api_server.py:155] waiting for model...
INFO 05-12 17:27:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:27:26 metrics.py:276] Avg prompt throughput: 4.6 tokens/s, Avg generation throughput: 11.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:36 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:39 api_server.py:182] release reload lock
INFO:     ::1:35152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:27:39 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:27:44 api_server.py:155] waiting for model...
INFO 05-12 17:27:44 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:27:44 metrics.py:276] Avg prompt throughput: 1.9 tokens/s, Avg generation throughput: 13.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:48 api_server.py:182] release reload lock
INFO:     ::1:35155 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:27:48 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:27:53 api_server.py:155] waiting for model...
INFO 05-12 17:27:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:27:53 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:27:58 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:03 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:08 api_server.py:182] release reload lock
INFO:     ::1:35156 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:28:08 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:28:12 api_server.py:155] waiting for model...
INFO 05-12 17:28:12 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:28:12 metrics.py:276] Avg prompt throughput: 2.3 tokens/s, Avg generation throughput: 15.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:17 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:18 api_server.py:182] release reload lock
INFO:     ::1:35164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:28:18 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:28:22 api_server.py:155] waiting for model...
INFO 05-12 17:28:22 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:28:22 metrics.py:276] Avg prompt throughput: 9.3 tokens/s, Avg generation throughput: 2.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:23 api_server.py:182] release reload lock
INFO:     ::1:35166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:28:23 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:28:27 api_server.py:155] waiting for model...
INFO 05-12 17:28:27 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:28:27 metrics.py:276] Avg prompt throughput: 9.8 tokens/s, Avg generation throughput: 2.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:32 api_server.py:182] release reload lock
INFO:     ::1:35171 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:28:32 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:28:36 api_server.py:155] waiting for model...
INFO 05-12 17:28:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:28:36 metrics.py:276] Avg prompt throughput: 2.0 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:40 api_server.py:182] release reload lock
INFO:     ::1:35172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:28:40 api_server.py:155] waiting for model...
INFO 05-12 17:28:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:28:41 metrics.py:276] Avg prompt throughput: 77.3 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:42 api_server.py:182] release reload lock
INFO:     ::1:35174 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:28:42 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:28:47 api_server.py:155] waiting for model...
INFO 05-12 17:28:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:28:47 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 4.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:50 api_server.py:182] release reload lock
INFO:     ::1:35176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:28:50 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:28:55 api_server.py:155] waiting for model...
INFO 05-12 17:28:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:28:55 metrics.py:276] Avg prompt throughput: 5.2 tokens/s, Avg generation throughput: 11.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:28:59 api_server.py:182] release reload lock
INFO:     ::1:35184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:28:59 async_llm_engine.py:437] Reloading model to /vllm/.idea/full_models/Llama-2-13b-hf
INFO 05-12 17:29:03 api_server.py:155] waiting for model...
INFO 05-12 17:29:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:29:03 metrics.py:276] Avg prompt throughput: 3.3 tokens/s, Avg generation throughput: 12.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:08 api_server.py:182] release reload lock
INFO:     ::1:35188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:29:08 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:29:13 api_server.py:155] waiting for model...
INFO 05-12 17:29:13 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:29:13 metrics.py:276] Avg prompt throughput: 2.3 tokens/s, Avg generation throughput: 15.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:18 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:19 api_server.py:182] release reload lock
INFO:     ::1:35192 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:29:19 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:29:24 api_server.py:155] waiting for model...
INFO 05-12 17:29:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:29:24 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 8.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:24 api_server.py:182] release reload lock
INFO:     ::1:35196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:29:24 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 17:29:29 api_server.py:155] waiting for model...
INFO 05-12 17:29:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:29:29 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 2.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:30 api_server.py:182] release reload lock
INFO:     ::1:35200 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:29:30 api_server.py:155] waiting for model...
INFO 05-12 17:29:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:29:31 api_server.py:182] release reload lock
INFO:     ::1:35204 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:29:31 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:29:36 api_server.py:155] waiting for model...
INFO 05-12 17:29:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:29:36 metrics.py:276] Avg prompt throughput: 4.5 tokens/s, Avg generation throughput: 8.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:38 api_server.py:182] release reload lock
INFO:     ::1:35206 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:29:38 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:29:42 api_server.py:155] waiting for model...
INFO 05-12 17:29:42 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:29:42 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:47 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 29.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:49 api_server.py:182] release reload lock
INFO:     ::1:35208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:29:49 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:29:54 api_server.py:155] waiting for model...
INFO 05-12 17:29:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:29:54 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:29:57 api_server.py:182] release reload lock
INFO:     ::1:35212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:29:57 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:30:02 api_server.py:155] waiting for model...
INFO 05-12 17:30:02 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:30:02 metrics.py:276] Avg prompt throughput: 31.7 tokens/s, Avg generation throughput: 12.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:05 api_server.py:182] release reload lock
INFO:     ::1:35214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:30:05 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:30:09 api_server.py:155] waiting for model...
INFO 05-12 17:30:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:30:09 metrics.py:276] Avg prompt throughput: 2.1 tokens/s, Avg generation throughput: 11.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:12 api_server.py:182] release reload lock
INFO:     ::1:35216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:30:12 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:30:17 api_server.py:155] waiting for model...
INFO 05-12 17:30:17 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:30:17 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:21 api_server.py:182] release reload lock
INFO:     ::1:35218 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:30:21 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:30:26 api_server.py:155] waiting for model...
INFO 05-12 17:30:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:30:26 metrics.py:276] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:31 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:33 api_server.py:182] release reload lock
INFO:     ::1:35224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:30:33 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:30:37 api_server.py:155] waiting for model...
INFO 05-12 17:30:37 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:30:37 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:42 metrics.py:276] Avg prompt throughput: 11.2 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:44 api_server.py:182] release reload lock
INFO:     ::1:35226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:30:44 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:30:49 api_server.py:155] waiting for model...
INFO 05-12 17:30:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:30:49 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:54 metrics.py:276] Avg prompt throughput: 4.6 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:30:59 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:04 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:06 api_server.py:182] release reload lock
INFO:     ::1:35228 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:31:06 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 17:31:10 api_server.py:155] waiting for model...
INFO 05-12 17:31:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:31:10 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:13 api_server.py:182] release reload lock
INFO:     ::1:35230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:31:13 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:31:17 api_server.py:155] waiting for model...
INFO 05-12 17:31:17 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:31:17 metrics.py:276] Avg prompt throughput: 6.3 tokens/s, Avg generation throughput: 10.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:18 api_server.py:182] release reload lock
INFO:     ::1:35232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:31:18 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 17:31:23 api_server.py:155] waiting for model...
INFO 05-12 17:31:23 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:31:23 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:28 metrics.py:276] Avg prompt throughput: 4.8 tokens/s, Avg generation throughput: 29.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:33 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:38 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:38 api_server.py:182] release reload lock
INFO:     ::1:35236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:31:38 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:31:43 api_server.py:155] waiting for model...
INFO 05-12 17:31:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:31:43 metrics.py:276] Avg prompt throughput: 8.0 tokens/s, Avg generation throughput: 3.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:47 api_server.py:182] release reload lock
INFO:     ::1:35238 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:31:47 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 17:31:52 api_server.py:155] waiting for model...
INFO 05-12 17:31:52 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:31:52 metrics.py:276] Avg prompt throughput: 2.1 tokens/s, Avg generation throughput: 15.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:31:56 api_server.py:182] release reload lock
INFO:     ::1:35240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:31:56 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 17:32:01 api_server.py:155] waiting for model...
INFO 05-12 17:32:01 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:32:01 metrics.py:276] Avg prompt throughput: 8.0 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:32:06 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 17:32:06 api_server.py:182] release reload lock
INFO:     ::1:35242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:32:06 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:32:11 api_server.py:155] waiting for model...
INFO 05-12 17:32:11 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:32:11 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 3.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:32:11 api_server.py:182] release reload lock
INFO:     ::1:35244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:32:11 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 17:32:15 api_server.py:155] waiting for model...
INFO 05-12 17:32:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:32:16 metrics.py:276] Avg prompt throughput: 4.6 tokens/s, Avg generation throughput: 3.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 17:32:16 api_server.py:182] release reload lock
INFO:     ::1:35246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 17:32:16 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 17:32:20 api_server.py:155] waiting for model...
INFO 05-12 17:32:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 17:32:21 metrics.py:276] Avg prompt throughput: 3.0 tokens/s, Avg generation throughput: 3.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
slurmstepd: error: *** JOB 3671411 ON HOST-10-140-60-6 CANCELLED AT 2024-05-12T18:19:50 ***
