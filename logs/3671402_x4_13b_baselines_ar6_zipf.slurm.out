/mnt/hwfile/huqinghao/miniconda3/bin/python
2024-05-12 10:08:39,303 - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-05-12 10:08:39,304 - INFO - Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2024-05-12 10:08:39,304 - INFO - NumExpr defaulting to 8 threads.
2024-05-12 10:08:40,224	INFO scripts.py:1182 -- Did not find any active Ray processes.

==========
== CUDA ==
==========

CUDA Version 12.1.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

*************************
** DEPRECATION NOTICE! **
*************************
THIS IMAGE IS DEPRECATED and is scheduled for DELETION.
    https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/support-policy.md

Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30148e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015270>: Failed to establish a new connection: [Errno 111] Connection refused'))
/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:160: UserWarning: Field "model_name_or_path" has conflict with protected namespace "model_".

You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
  warnings.warn(
INFO 05-12 10:08:57 api_server.py:219] vLLM API server version 0.3.3
INFO 05-12 10:08:57 api_server.py:220] args: Namespace(host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=[], delta_modules=[], swap_modules=[SwapModule(name='delta-1', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-1'), SwapModule(name='delta-2', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-2'), SwapModule(name='delta-3', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-3'), SwapModule(name='delta-4', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-4'), SwapModule(name='delta-5', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-5'), SwapModule(name='delta-6', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-6'), SwapModule(name='delta-7', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-7'), SwapModule(name='delta-8', local_path='/vllm/.idea/full_models/Llama-2-13b-hf-8')], chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='auto', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=4, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, seed=0, swap_space=4, gpu_memory_utilization=0.85, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=True, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=64, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=32, enable_delta=False, max_deltas=0, max_cpu_deltas=32, max_delta_bitwidth=4, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_prefetch=False, scheduler_policy='fcfs', engine_use_ray=False, disable_log_requests=True, max_log_len=None)
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015330>: Failed to establish a new connection: [Errno 111] Connection refused'))
2024-05-12 10:09:01,169	INFO worker.py:1749 -- Started a local Ray instance.
INFO 05-12 10:09:03 llm_engine.py:87] Initializing an LLM engine (v0.3.3) with config: model='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer='/vllm/.idea/full_models/Llama-2-13b-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, lora_config=None, delta_config=None, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014040>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015b40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016410>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016ce0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016ad0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016200>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015930>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014250>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015360>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b34437c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30142b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015960>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016230>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016b00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30175b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016d40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016770>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015ea0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30147c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014f70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017280>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30140a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015b70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016440>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016f80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016830>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30179d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017160>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016620>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015d50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014f10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017340>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015960>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016230>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016b00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017730>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017ac0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017ac0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017730>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016b00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016230>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30143d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017e80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014490>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016080>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30178e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30177f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014e80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017490>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016ef0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016dd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017040>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015a80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30149a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015b10>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30163e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016b90>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO 05-12 10:18:49 selector.py:16] Using FlashAttention backend.
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017ee0>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=119520)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7fc0ad948e50>
[36m(RayWorkerVllm pid=119520)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=119520)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=119520)[0m     self.remove()
[36m(RayWorkerVllm pid=119520)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=119520)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=119520)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
[36m(RayWorkerVllm pid=119642)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7f74880e0e50>
[36m(RayWorkerVllm pid=119642)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=119642)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=119642)[0m     self.remove()
[36m(RayWorkerVllm pid=119642)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=119642)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=119642)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017d90>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=119642)[0m Exception ignored in: <function TempDirectory.__del__ at 0x7f74880e0e50>
[36m(RayWorkerVllm pid=119642)[0m Traceback (most recent call last):
[36m(RayWorkerVllm pid=119642)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 145, in __del__
[36m(RayWorkerVllm pid=119642)[0m     self.remove()
[36m(RayWorkerVllm pid=119642)[0m   File "/usr/local/lib/python3.10/dist-packages/bitblas/3rdparty/tvm/python/tvm/contrib/utils.py", line 121, in remove
[36m(RayWorkerVllm pid=119642)[0m     if self.temp_dir:
[36m(RayWorkerVllm pid=119642)[0m AttributeError: 'TempDirectory' object has no attribute 'temp_dir'
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015000>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016ec0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015bd0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014280>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30587c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30170d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016b60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017460>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015150>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3058370>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017e50>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017d60>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30173a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016da0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30143a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30580d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016b30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016800>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017790>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014fa0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3058a00>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30152a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30177f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30178e0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30170d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014790>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30590c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016050>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016c20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017a30>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015750>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3058580>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30168f0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017c40>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017670>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016fb0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30144c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30158d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017040>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017640>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30164a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015690>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017f70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017f70>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015690>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30164a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017640>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30159c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014b80>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016410>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b30175b0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3016f20>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3014c40>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=119520)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=119520)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=119642)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=119642)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=119642)[0m BitBLAS Operator not loaded, retrying in 5 seconds...
[36m(RayWorkerVllm pid=119642)[0m Error: [Errno 17] File exists: '/home/xiayao/.cache/bitblas/nvidia/nvidia-a100/c96df0f34eb23be516ef0126651d4e78b151337f28ebc87cc5492d79d135855f/tvm_rt_mod'
[36m(RayWorkerVllm pid=119247)[0m INFO 05-12 10:27:35 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=119520)[0m INFO 05-12 10:27:40 selector.py:16] Using FlashAttention backend.
[36m(RayWorkerVllm pid=119642)[0m INFO 05-12 10:27:44 selector.py:16] Using FlashAttention backend.
INFO 05-12 10:27:58 model_runner.py:155] Loading model weights took 6.1114 GB
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3015060>: Failed to establish a new connection: [Errno 111] Connection refused'))
Waiting for 10 secs for the system to be ready: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sysinfo (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f48b3017f40>: Failed to establish a new connection: [Errno 111] Connection refused'))
[36m(RayWorkerVllm pid=119247)[0m INFO 05-12 10:28:00 model_runner.py:155] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=119642)[0m INFO 05-12 10:28:00 model_runner.py:155] Loading model weights took 6.1114 GB
[36m(RayWorkerVllm pid=119520)[0m INFO 05-12 10:28:00 model_runner.py:155] Loading model weights took 6.1114 GB
INFO 05-12 10:28:12 ray_gpu_executor.py:266] # GPU blocks: 19075, # CPU blocks: 1310
INFO 05-12 10:28:15 block_manager.py:264] disable automatic prefix caching
WARNING 05-12 10:28:15 serving_chat.py:373] No chat template provided. Chat API will not work.
INFO:     Started server process [111013]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     ::1:39856 - "GET /sysinfo HTTP/1.1" 200 OK
Translating from base-model to /vllm/.idea/full_models/Llama-2-13b-hf
Warming up starts
{'id': 127, 'prompt': 'USER: An urn contains 15 blue marbles, 15 red marbles, and 10 green marbles. If I pull marbles from the urn one at a time, without replacing them, how many times will I have to pull (on average) before I see 3 green marbles? \nASSISTANT:', 'timestamp': 0, 'model': 'delta-2', 'min_tokens': 440, 'max_tokens': 440}
INFO 05-12 10:28:21 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:21 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:28:26 api_server.py:155] waiting for model...
INFO 05-12 10:28:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:26 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 10:28:31 metrics.py:276] Avg prompt throughput: 14.9 tokens/s, Avg generation throughput: 27.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 10:28:36 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 10:28:41 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO:     ::1:39858 - "POST /v1/completions HTTP/1.1" 200 OK
Warming up ends
Issuing queries
sending 1 queries at 0.2
sending 1 queries at 0.4
sending 1 queries at 0.5
sending 1 queries at 0.7000000000000001
sending 1 queries at 0.8
sending 1 queries at 0.9
sending 1 queries at 1.0
sending 1 queries at 1.4000000000000001
sending 2 queries at 2.0
sending 1 queries at 2.3000000000000003
sending 1 queries at 2.4000000000000004
sending 1 queries at 2.6
sending 4 queries at 3.0
sending 1 queries at 3.3000000000000003
sending 1 queries at 3.6
sending 1 queries at 3.9000000000000004
sending 1 queries at 4.6000000000000005
sending 1 queries at 4.800000000000001
sending 1 queries at 4.9
sending 2 queries at 5.2
sending 2 queries at 5.4
sending 1 queries at 5.9
sending 1 queries at 6.0
sending 2 queries at 6.1000000000000005
sending 1 queries at 6.4
sending 1 queries at 6.5
sending 2 queries at 6.6000000000000005
sending 1 queries at 6.800000000000001
sending 1 queries at 7.0
sending 1 queries at 7.1000000000000005
sending 1 queries at 7.6000000000000005
sending 1 queries at 7.800000000000001
sending 1 queries at 7.9
sending 1 queries at 8.0
sending 2 queries at 8.200000000000001
sending 1 queries at 8.4
sending 1 queries at 8.5
sending 2 queries at 8.6
sending 2 queries at 8.700000000000001
sending 1 queries at 8.9
sending 1 queries at 9.0
sending 2 queries at 9.700000000000001
sending 2 queries at 9.8
sending 2 queries at 10.0
sending 1 queries at 10.100000000000001
sending 3 queries at 10.200000000000001
sending 2 queries at 10.4
sending 2 queries at 10.5
sending 2 queries at 10.8
sending 2 queries at 11.200000000000001
sending 1 queries at 11.8
sending 1 queries at 11.9
sending 1 queries at 12.5
sending 1 queries at 12.700000000000001
sending 2 queries at 12.9
sending 3 queries at 13.0
sending 2 queries at 13.100000000000001
sending 2 queries at 13.200000000000001
sending 1 queries at 13.4
sending 2 queries at 13.600000000000001
sending 1 queries at 13.700000000000001
sending 1 queries at 13.8
sending 1 queries at 13.9
sending 1 queries at 14.3
sending 1 queries at 14.4
sending 2 queries at 14.600000000000001
sending 1 queries at 14.8
sending 2 queries at 14.9
sending 2 queries at 15.100000000000001
sending 2 queries at 15.4
sending 1 queries at 15.5
sending 1 queries at 15.600000000000001
sending 1 queries at 15.8
sending 2 queries at 16.400000000000002
sending 1 queries at 16.6
sending 1 queries at 16.7
sending 2 queries at 16.900000000000002
sending 1 queries at 17.400000000000002
sending 1 queries at 17.5
sending 1 queries at 17.8
sending 1 queries at 18.0
sending 1 queries at 18.1
sending 2 queries at 18.400000000000002
sending 1 queries at 18.8
sending 1 queries at 18.900000000000002
sending 1 queries at 19.3
sending 1 queries at 19.5
sending 1 queries at 19.700000000000003
sending 1 queries at 19.8
sending 1 queries at 20.3
sending 1 queries at 20.5
sending 1 queries at 20.6
sending 3 queries at 20.8
sending 1 queries at 21.0
sending 1 queries at 21.1
sending 1 queries at 21.200000000000003
sending 2 queries at 21.3
sending 1 queries at 21.400000000000002
sending 1 queries at 21.5
sending 1 queries at 21.700000000000003
sending 1 queries at 21.8
sending 1 queries at 22.0
sending 1 queries at 22.200000000000003
sending 1 queries at 22.3
sending 2 queries at 22.700000000000003
sending 1 queries at 22.8
sending 1 queries at 23.200000000000003
sending 1 queries at 23.5
sending 2 queries at 23.700000000000003
sending 1 queries at 24.1
sending 1 queries at 24.3
sending 1 queries at 25.400000000000002
sending 1 queries at 25.5
sending 2 queries at 25.8
sending 2 queries at 26.0
sending 1 queries at 26.3
sending 1 queries at 26.6
sending 2 queries at 26.8
sending 1 queries at 26.900000000000002
sending 1 queries at 27.0
sending 1 queries at 27.200000000000003
sending 1 queries at 27.400000000000002
sending 1 queries at 27.700000000000003
sending 1 queries at 28.3
sending 2 queries at 28.6
sending 1 queries at 28.700000000000003
sending 1 queries at 28.900000000000002
sending 1 queries at 29.0
sending 4 queries at 29.1
sending 2 queries at 29.400000000000002
sending 1 queries at 29.5
sending 1 queries at 30.0
INFO 05-12 10:28:42 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:42 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:28:46 api_server.py:155] waiting for model...
INFO 05-12 10:28:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:46 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2.6 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 05-12 10:28:46 api_server.py:155] waiting for model...
INFO 05-12 10:28:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:155] waiting for model...
INFO 05-12 10:28:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:46 api_server.py:155] waiting for model...
INFO 05-12 10:28:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:46 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:47 api_server.py:155] waiting for model...
INFO 05-12 10:28:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:47 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:48 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:48 api_server.py:134] Waiting for reload lock...
INFO:     ::1:39972 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:28:48 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:28:53 api_server.py:155] waiting for model...
INFO 05-12 10:28:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 metrics.py:276] Avg prompt throughput: 21.9 tokens/s, Avg generation throughput: 26.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:155] waiting for model...
INFO 05-12 10:28:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:155] waiting for model...
INFO 05-12 10:28:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:155] waiting for model...
INFO 05-12 10:28:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:155] waiting for model...
INFO 05-12 10:28:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:155] waiting for model...
INFO 05-12 10:28:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:155] waiting for model...
INFO 05-12 10:28:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:53 api_server.py:134] Waiting for reload lock...
INFO:     ::1:39966 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:28:53 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 metrics.py:276] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 27.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:155] waiting for model...
INFO 05-12 10:28:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:28:58 api_server.py:134] Waiting for reload lock...
INFO:     ::1:40118 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:28:58 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:29:03 api_server.py:155] waiting for model...
INFO 05-12 10:29:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 metrics.py:276] Avg prompt throughput: 43.8 tokens/s, Avg generation throughput: 27.6 tokens/s, Running: 19 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:155] waiting for model...
INFO 05-12 10:29:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:03 api_server.py:155] waiting for model...
INFO 05-12 10:29:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:155] waiting for model...
INFO 05-12 10:29:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:155] waiting for model...
INFO 05-12 10:29:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:155] waiting for model...
INFO 05-12 10:29:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:155] waiting for model...
INFO 05-12 10:29:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:03 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:04 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:04 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:04 api_server.py:155] waiting for model...
INFO 05-12 10:29:04 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40038 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:04 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:09 metrics.py:276] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 92.7 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO:     ::1:40296 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:09 api_server.py:134] Waiting for reload lock...
INFO:     ::1:40114 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:09 api_server.py:155] waiting for model...
INFO 05-12 10:29:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:39940 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40078 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:10 async_llm_engine.py:437] Reloading model to delta-4
total threads: 178
INFO 05-12 10:29:15 api_server.py:155] waiting for model...
INFO 05-12 10:29:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 metrics.py:276] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 119.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:155] waiting for model...
INFO 05-12 10:29:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO 05-12 10:29:15 api_server.py:134] Waiting for reload lock...
INFO:     ::1:40258 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:15 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:29:20 api_server.py:155] waiting for model...
INFO 05-12 10:29:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40116 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:20 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:29:24 api_server.py:155] waiting for model...
INFO 05-12 10:29:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:24 metrics.py:276] Avg prompt throughput: 5.5 tokens/s, Avg generation throughput: 7.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%
INFO:     ::1:39946 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:25 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:29:29 api_server.py:155] waiting for model...
INFO 05-12 10:29:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:29 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 32.7 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO:     ::1:40318 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:30 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:29:34 api_server.py:155] waiting for model...
INFO 05-12 10:29:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:39936 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:34 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:29:40 api_server.py:155] waiting for model...
INFO 05-12 10:29:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:40 metrics.py:276] Avg prompt throughput: 9.1 tokens/s, Avg generation throughput: 6.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%
INFO:     ::1:39932 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:40 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:29:45 api_server.py:155] waiting for model...
INFO 05-12 10:29:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:45 metrics.py:276] Avg prompt throughput: 11.6 tokens/s, Avg generation throughput: 64.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%
INFO:     ::1:39954 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:45 api_server.py:155] waiting for model...
INFO 05-12 10:29:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40196 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:45 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 10:29:50 api_server.py:155] waiting for model...
INFO 05-12 10:29:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:50 metrics.py:276] Avg prompt throughput: 6.5 tokens/s, Avg generation throughput: 32.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%
INFO:     ::1:39942 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:51 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:29:55 api_server.py:155] waiting for model...
INFO 05-12 10:29:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:29:55 metrics.py:276] Avg prompt throughput: 3.3 tokens/s, Avg generation throughput: 114.5 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:39925 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:29:55 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:30:00 api_server.py:155] waiting for model...
INFO 05-12 10:30:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:39934 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:00 api_server.py:155] waiting for model...
INFO 05-12 10:30:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:00 metrics.py:276] Avg prompt throughput: 19.1 tokens/s, Avg generation throughput: 19.9 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:40206 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:00 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:30:05 api_server.py:155] waiting for model...
INFO 05-12 10:30:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:05 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 19.6 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:39956 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:06 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:30:10 api_server.py:155] waiting for model...
INFO 05-12 10:30:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:10 metrics.py:276] Avg prompt throughput: 3.0 tokens/s, Avg generation throughput: 45.3 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:40278 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:11 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:30:16 api_server.py:155] waiting for model...
INFO 05-12 10:30:16 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:16 metrics.py:276] Avg prompt throughput: 4.6 tokens/s, Avg generation throughput: 44.4 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:39978 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:16 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:30:21 api_server.py:155] waiting for model...
INFO 05-12 10:30:21 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:21 metrics.py:276] Avg prompt throughput: 6.3 tokens/s, Avg generation throughput: 38.8 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:39922 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40232 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:21 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:30:26 api_server.py:155] waiting for model...
INFO 05-12 10:30:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:26 metrics.py:276] Avg prompt throughput: 5.5 tokens/s, Avg generation throughput: 50.4 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:39948 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:27 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:30:31 api_server.py:155] waiting for model...
INFO 05-12 10:30:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:31 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 84.2 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:39986 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:31 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:30:36 api_server.py:155] waiting for model...
INFO 05-12 10:30:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40158 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:36 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:30:41 api_server.py:155] waiting for model...
INFO 05-12 10:30:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:41 metrics.py:276] Avg prompt throughput: 4.6 tokens/s, Avg generation throughput: 13.0 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:39990 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:41 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:30:46 api_server.py:155] waiting for model...
INFO 05-12 10:30:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40178 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:46 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:30:51 api_server.py:155] waiting for model...
INFO 05-12 10:30:51 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:51 metrics.py:276] Avg prompt throughput: 3.1 tokens/s, Avg generation throughput: 22.8 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:39992 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:39994 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:51 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:30:56 api_server.py:155] waiting for model...
INFO 05-12 10:30:56 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:30:56 metrics.py:276] Avg prompt throughput: 13.3 tokens/s, Avg generation throughput: 38.1 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:39950 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:30:56 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:31:01 api_server.py:155] waiting for model...
INFO 05-12 10:31:01 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:01 metrics.py:276] Avg prompt throughput: 3.9 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:39944 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:01 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:31:06 api_server.py:155] waiting for model...
INFO 05-12 10:31:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:06 metrics.py:276] Avg prompt throughput: 11.5 tokens/s, Avg generation throughput: 24.7 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:39996 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:06 api_server.py:155] waiting for model...
INFO 05-12 10:31:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:39998 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:06 api_server.py:155] waiting for model...
INFO 05-12 10:31:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40014 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:07 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:31:11 api_server.py:155] waiting for model...
INFO 05-12 10:31:11 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:11 metrics.py:276] Avg prompt throughput: 9.5 tokens/s, Avg generation throughput: 58.2 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:39962 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:12 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:31:17 api_server.py:155] waiting for model...
INFO 05-12 10:31:17 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:17 metrics.py:276] Avg prompt throughput: 3.5 tokens/s, Avg generation throughput: 86.0 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:39960 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:17 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:31:22 api_server.py:155] waiting for model...
INFO 05-12 10:31:22 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:22 metrics.py:276] Avg prompt throughput: 10.2 tokens/s, Avg generation throughput: 18.8 tokens/s, Running: 31 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:39926 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:22 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:31:27 api_server.py:155] waiting for model...
INFO 05-12 10:31:27 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:27 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 36.5 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40182 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:27 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:31:32 api_server.py:155] waiting for model...
INFO 05-12 10:31:32 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40016 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:32 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:31:37 api_server.py:155] waiting for model...
INFO 05-12 10:31:37 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:37 metrics.py:276] Avg prompt throughput: 3.6 tokens/s, Avg generation throughput: 18.9 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40110 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40294 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:37 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 10:31:42 api_server.py:155] waiting for model...
INFO 05-12 10:31:42 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:42 metrics.py:276] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 6.4 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40044 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:42 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:31:47 api_server.py:155] waiting for model...
INFO 05-12 10:31:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:47 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 67.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40026 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:47 api_server.py:155] waiting for model...
INFO 05-12 10:31:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40140 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:48 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:31:52 api_server.py:155] waiting for model...
INFO 05-12 10:31:52 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:52 metrics.py:276] Avg prompt throughput: 7.0 tokens/s, Avg generation throughput: 51.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40088 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40068 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:53 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:31:57 api_server.py:155] waiting for model...
INFO 05-12 10:31:57 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:31:57 metrics.py:276] Avg prompt throughput: 8.2 tokens/s, Avg generation throughput: 46.9 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40264 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:31:58 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:32:02 api_server.py:155] waiting for model...
INFO 05-12 10:32:02 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:02 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:39974 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:03 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:32:08 api_server.py:155] waiting for model...
INFO 05-12 10:32:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:08 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 69.5 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40018 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:08 api_server.py:155] waiting for model...
INFO 05-12 10:32:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40002 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:08 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:32:13 api_server.py:155] waiting for model...
INFO 05-12 10:32:13 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:13 metrics.py:276] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 59.8 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:39984 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:14 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:32:19 api_server.py:155] waiting for model...
INFO 05-12 10:32:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:19 metrics.py:276] Avg prompt throughput: 3.9 tokens/s, Avg generation throughput: 53.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40028 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:19 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:32:23 api_server.py:155] waiting for model...
INFO 05-12 10:32:23 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:39968 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:24 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:32:28 api_server.py:155] waiting for model...
INFO 05-12 10:32:28 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:28 metrics.py:276] Avg prompt throughput: 4.0 tokens/s, Avg generation throughput: 6.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40244 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:29 api_server.py:155] waiting for model...
INFO 05-12 10:32:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:39938 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:29 api_server.py:155] waiting for model...
INFO 05-12 10:32:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40053 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:30 api_server.py:155] waiting for model...
INFO 05-12 10:32:30 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:39928 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:30 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:32:35 api_server.py:155] waiting for model...
INFO 05-12 10:32:35 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:35 metrics.py:276] Avg prompt throughput: 17.1 tokens/s, Avg generation throughput: 178.6 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40060 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:35 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:32:40 api_server.py:155] waiting for model...
INFO 05-12 10:32:40 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:40 metrics.py:276] Avg prompt throughput: 5.3 tokens/s, Avg generation throughput: 28.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40024 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:40 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 10:32:45 api_server.py:155] waiting for model...
INFO 05-12 10:32:45 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40040 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:45 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:32:50 api_server.py:155] waiting for model...
INFO 05-12 10:32:50 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:50 metrics.py:276] Avg prompt throughput: 6.8 tokens/s, Avg generation throughput: 17.8 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40058 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:50 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:32:55 api_server.py:155] waiting for model...
INFO 05-12 10:32:55 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:32:55 metrics.py:276] Avg prompt throughput: 9.4 tokens/s, Avg generation throughput: 65.6 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:40004 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:32:55 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:33:00 api_server.py:155] waiting for model...
INFO 05-12 10:33:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:00 metrics.py:276] Avg prompt throughput: 3.2 tokens/s, Avg generation throughput: 5.7 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:40020 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:01 api_server.py:155] waiting for model...
INFO 05-12 10:33:01 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:39958 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:01 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:33:06 api_server.py:155] waiting for model...
INFO 05-12 10:33:06 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:06 metrics.py:276] Avg prompt throughput: 55.5 tokens/s, Avg generation throughput: 126.2 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:39976 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:06 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:33:11 api_server.py:155] waiting for model...
INFO 05-12 10:33:11 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:11 metrics.py:276] Avg prompt throughput: 2.0 tokens/s, Avg generation throughput: 22.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:40032 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:11 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:33:16 api_server.py:155] waiting for model...
INFO 05-12 10:33:16 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:16 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.9%, CPU KV cache usage: 0.0%
INFO:     ::1:40094 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:17 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:33:21 api_server.py:155] waiting for model...
INFO 05-12 10:33:21 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:21 metrics.py:276] Avg prompt throughput: 74.0 tokens/s, Avg generation throughput: 35.0 tokens/s, Running: 28 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO:     ::1:40254 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:22 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:33:26 api_server.py:155] waiting for model...
INFO 05-12 10:33:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40098 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40102 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:26 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:33:31 api_server.py:155] waiting for model...
INFO 05-12 10:33:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:31 metrics.py:276] Avg prompt throughput: 1.7 tokens/s, Avg generation throughput: 5.9 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40070 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40006 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:32 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:33:36 api_server.py:155] waiting for model...
INFO 05-12 10:33:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:36 metrics.py:276] Avg prompt throughput: 9.2 tokens/s, Avg generation throughput: 44.0 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40093 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:36 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:33:41 api_server.py:155] waiting for model...
INFO 05-12 10:33:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:41 metrics.py:276] Avg prompt throughput: 7.0 tokens/s, Avg generation throughput: 11.0 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40064 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40046 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:42 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:33:47 api_server.py:155] waiting for model...
INFO 05-12 10:33:47 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:47 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 109.9 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40036 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:47 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:33:52 api_server.py:155] waiting for model...
INFO 05-12 10:33:52 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:52 metrics.py:276] Avg prompt throughput: 7.6 tokens/s, Avg generation throughput: 10.6 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40104 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:53 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:33:57 api_server.py:155] waiting for model...
INFO 05-12 10:33:57 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:33:57 metrics.py:276] Avg prompt throughput: 10.0 tokens/s, Avg generation throughput: 46.7 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO:     ::1:39988 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:33:58 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:34:03 api_server.py:155] waiting for model...
INFO 05-12 10:34:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:03 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 49.6 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40112 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:03 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:34:07 api_server.py:155] waiting for model...
INFO 05-12 10:34:07 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40124 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:07 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:34:12 api_server.py:155] waiting for model...
INFO 05-12 10:34:12 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:12 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 10.7 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40030 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:12 async_llm_engine.py:437] Reloading model to delta-1
INFO 05-12 10:34:17 api_server.py:155] waiting for model...
INFO 05-12 10:34:17 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:17 metrics.py:276] Avg prompt throughput: 8.1 tokens/s, Avg generation throughput: 46.7 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40228 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:18 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:34:23 api_server.py:155] waiting for model...
INFO 05-12 10:34:23 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:23 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 48.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40100 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:23 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:34:27 api_server.py:155] waiting for model...
INFO 05-12 10:34:27 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:28 metrics.py:276] Avg prompt throughput: 9.9 tokens/s, Avg generation throughput: 15.9 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40108 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:28 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:34:33 api_server.py:155] waiting for model...
INFO 05-12 10:34:33 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:33 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.9 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40072 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:34 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:34:38 api_server.py:155] waiting for model...
INFO 05-12 10:34:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:38 metrics.py:276] Avg prompt throughput: 5.7 tokens/s, Avg generation throughput: 95.0 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40066 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:39 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:34:43 api_server.py:155] waiting for model...
INFO 05-12 10:34:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:43 metrics.py:276] Avg prompt throughput: 3.7 tokens/s, Avg generation throughput: 35.7 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40050 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:43 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:34:48 api_server.py:155] waiting for model...
INFO 05-12 10:34:48 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:48 metrics.py:276] Avg prompt throughput: 7.1 tokens/s, Avg generation throughput: 20.8 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40062 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:49 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:34:54 api_server.py:155] waiting for model...
INFO 05-12 10:34:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:54 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 24.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40126 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:54 api_server.py:155] waiting for model...
INFO 05-12 10:34:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40154 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:54 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:34:59 api_server.py:155] waiting for model...
INFO 05-12 10:34:59 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:34:59 metrics.py:276] Avg prompt throughput: 18.0 tokens/s, Avg generation throughput: 48.7 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40086 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:34:59 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:35:04 api_server.py:155] waiting for model...
INFO 05-12 10:35:04 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:04 metrics.py:276] Avg prompt throughput: 3.5 tokens/s, Avg generation throughput: 30.0 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40022 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:04 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:35:09 api_server.py:155] waiting for model...
INFO 05-12 10:35:09 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:09 metrics.py:276] Avg prompt throughput: 81.1 tokens/s, Avg generation throughput: 26.2 tokens/s, Running: 26 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40136 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:09 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:35:14 api_server.py:155] waiting for model...
INFO 05-12 10:35:14 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:14 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 34.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%
INFO:     ::1:39980 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:15 api_server.py:155] waiting for model...
INFO 05-12 10:35:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40080 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:15 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:35:20 api_server.py:155] waiting for model...
INFO 05-12 10:35:20 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:20 metrics.py:276] Avg prompt throughput: 7.3 tokens/s, Avg generation throughput: 30.1 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:39952 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:20 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:35:25 api_server.py:155] waiting for model...
INFO 05-12 10:35:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:25 metrics.py:276] Avg prompt throughput: 7.1 tokens/s, Avg generation throughput: 81.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40048 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:25 api_server.py:155] waiting for model...
INFO 05-12 10:35:25 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40150 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:26 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:35:31 api_server.py:155] waiting for model...
INFO 05-12 10:35:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:31 metrics.py:276] Avg prompt throughput: 8.3 tokens/s, Avg generation throughput: 19.9 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40084 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:31 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:35:36 api_server.py:155] waiting for model...
INFO 05-12 10:35:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:36 metrics.py:276] Avg prompt throughput: 3.4 tokens/s, Avg generation throughput: 46.5 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40186 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:36 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:35:41 api_server.py:155] waiting for model...
INFO 05-12 10:35:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:41 metrics.py:276] Avg prompt throughput: 4.2 tokens/s, Avg generation throughput: 10.5 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40188 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40090 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:41 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:35:46 api_server.py:155] waiting for model...
INFO 05-12 10:35:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:46 metrics.py:276] Avg prompt throughput: 3.1 tokens/s, Avg generation throughput: 61.3 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:40166 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:46 api_server.py:155] waiting for model...
INFO 05-12 10:35:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40144 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:46 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:35:51 api_server.py:155] waiting for model...
INFO 05-12 10:35:51 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:51 metrics.py:276] Avg prompt throughput: 13.3 tokens/s, Avg generation throughput: 25.2 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40056 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:51 api_server.py:155] waiting for model...
INFO 05-12 10:35:51 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40096 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:52 api_server.py:155] waiting for model...
INFO 05-12 10:35:52 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40194 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:52 api_server.py:155] waiting for model...
INFO 05-12 10:35:52 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40164 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:52 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:35:57 api_server.py:155] waiting for model...
INFO 05-12 10:35:57 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:35:57 metrics.py:276] Avg prompt throughput: 78.5 tokens/s, Avg generation throughput: 120.6 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40168 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:35:57 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:36:02 api_server.py:155] waiting for model...
INFO 05-12 10:36:02 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:02 metrics.py:276] Avg prompt throughput: 18.9 tokens/s, Avg generation throughput: 35.0 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40106 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:02 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:36:07 api_server.py:155] waiting for model...
INFO 05-12 10:36:07 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:07 metrics.py:276] Avg prompt throughput: 11.1 tokens/s, Avg generation throughput: 19.8 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40120 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:07 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:36:12 api_server.py:155] waiting for model...
INFO 05-12 10:36:12 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:12 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40162 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:12 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:36:17 api_server.py:155] waiting for model...
INFO 05-12 10:36:17 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:17 metrics.py:276] Avg prompt throughput: 8.3 tokens/s, Avg generation throughput: 20.1 tokens/s, Running: 25 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40176 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:18 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:36:22 api_server.py:155] waiting for model...
INFO 05-12 10:36:22 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:22 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 29.7 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40152 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:23 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:36:27 api_server.py:155] waiting for model...
INFO 05-12 10:36:27 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:27 metrics.py:276] Avg prompt throughput: 3.1 tokens/s, Avg generation throughput: 53.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40074 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:28 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:36:33 api_server.py:155] waiting for model...
INFO 05-12 10:36:33 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:33 metrics.py:276] Avg prompt throughput: 5.3 tokens/s, Avg generation throughput: 14.8 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:40148 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:33 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:36:38 api_server.py:155] waiting for model...
INFO 05-12 10:36:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:38 metrics.py:276] Avg prompt throughput: 7.7 tokens/s, Avg generation throughput: 67.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40201 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:38 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:36:43 api_server.py:155] waiting for model...
INFO 05-12 10:36:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:43 metrics.py:276] Avg prompt throughput: 13.7 tokens/s, Avg generation throughput: 29.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40205 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40226 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:43 api_server.py:155] waiting for model...
INFO 05-12 10:36:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40170 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:43 api_server.py:155] waiting for model...
INFO 05-12 10:36:43 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40202 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:43 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:36:48 api_server.py:155] waiting for model...
INFO 05-12 10:36:48 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:48 metrics.py:276] Avg prompt throughput: 10.9 tokens/s, Avg generation throughput: 33.5 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:40236 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:48 async_llm_engine.py:437] Reloading model to delta-3
INFO 05-12 10:36:53 api_server.py:155] waiting for model...
INFO 05-12 10:36:53 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:53 metrics.py:276] Avg prompt throughput: 14.0 tokens/s, Avg generation throughput: 19.4 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:40240 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:53 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:36:58 api_server.py:155] waiting for model...
INFO 05-12 10:36:58 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:36:58 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 18.9 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:40210 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:36:58 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:37:03 api_server.py:155] waiting for model...
INFO 05-12 10:37:03 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:03 metrics.py:276] Avg prompt throughput: 8.2 tokens/s, Avg generation throughput: 57.5 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40222 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:03 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:37:08 api_server.py:155] waiting for model...
INFO 05-12 10:37:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:08 metrics.py:276] Avg prompt throughput: 3.8 tokens/s, Avg generation throughput: 23.9 tokens/s, Running: 24 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40208 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:08 api_server.py:155] waiting for model...
INFO 05-12 10:37:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40224 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40262 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:08 api_server.py:155] waiting for model...
INFO 05-12 10:37:08 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40172 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:09 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:37:13 api_server.py:155] waiting for model...
INFO 05-12 10:37:13 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:13 metrics.py:276] Avg prompt throughput: 11.7 tokens/s, Avg generation throughput: 55.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%
INFO:     ::1:40128 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:14 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:37:19 api_server.py:155] waiting for model...
INFO 05-12 10:37:19 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:19 metrics.py:276] Avg prompt throughput: 5.3 tokens/s, Avg generation throughput: 89.9 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40250 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:19 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:37:24 api_server.py:155] waiting for model...
INFO 05-12 10:37:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:24 metrics.py:276] Avg prompt throughput: 16.5 tokens/s, Avg generation throughput: 27.7 tokens/s, Running: 23 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40276 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:24 api_server.py:155] waiting for model...
INFO 05-12 10:37:24 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40272 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:24 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:37:29 api_server.py:155] waiting for model...
INFO 05-12 10:37:29 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:29 metrics.py:276] Avg prompt throughput: 2.2 tokens/s, Avg generation throughput: 50.2 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:40184 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:29 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:37:34 api_server.py:155] waiting for model...
INFO 05-12 10:37:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:34 metrics.py:276] Avg prompt throughput: 7.0 tokens/s, Avg generation throughput: 23.2 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40282 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:34 api_server.py:155] waiting for model...
INFO 05-12 10:37:34 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40286 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40284 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:34 async_llm_engine.py:437] Reloading model to delta-4
INFO 05-12 10:37:38 api_server.py:155] waiting for model...
INFO 05-12 10:37:38 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:39 metrics.py:276] Avg prompt throughput: 10.0 tokens/s, Avg generation throughput: 53.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:40199 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:39 api_server.py:155] waiting for model...
INFO 05-12 10:37:39 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40257 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:39 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:37:44 api_server.py:155] waiting for model...
INFO 05-12 10:37:44 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:44 metrics.py:276] Avg prompt throughput: 6.4 tokens/s, Avg generation throughput: 46.6 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:40132 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:44 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:37:49 api_server.py:155] waiting for model...
INFO 05-12 10:37:49 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:49 metrics.py:276] Avg prompt throughput: 87.6 tokens/s, Avg generation throughput: 35.0 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40230 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:49 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:37:54 api_server.py:155] waiting for model...
INFO 05-12 10:37:54 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:37:54 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 17.2 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40212 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:37:55 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:38:00 api_server.py:155] waiting for model...
INFO 05-12 10:38:00 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:00 metrics.py:276] Avg prompt throughput: 6.0 tokens/s, Avg generation throughput: 63.4 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40292 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:00 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:38:05 api_server.py:155] waiting for model...
INFO 05-12 10:38:05 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:05 metrics.py:276] Avg prompt throughput: 10.9 tokens/s, Avg generation throughput: 4.6 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40234 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:05 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:38:10 api_server.py:155] waiting for model...
INFO 05-12 10:38:10 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:10 metrics.py:276] Avg prompt throughput: 6.5 tokens/s, Avg generation throughput: 58.9 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40216 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:10 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:38:15 api_server.py:155] waiting for model...
INFO 05-12 10:38:15 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:15 metrics.py:276] Avg prompt throughput: 7.0 tokens/s, Avg generation throughput: 4.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40134 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:16 api_server.py:155] waiting for model...
INFO 05-12 10:38:16 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40260 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:16 async_llm_engine.py:437] Reloading model to delta-7
INFO 05-12 10:38:21 api_server.py:155] waiting for model...
INFO 05-12 10:38:21 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:21 metrics.py:276] Avg prompt throughput: 17.9 tokens/s, Avg generation throughput: 75.6 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40190 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:21 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:38:26 api_server.py:155] waiting for model...
INFO 05-12 10:38:26 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:26 metrics.py:276] Avg prompt throughput: 3.5 tokens/s, Avg generation throughput: 4.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:40142 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:26 async_llm_engine.py:437] Reloading model to delta-6
INFO 05-12 10:38:31 api_server.py:155] waiting for model...
INFO 05-12 10:38:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:31 metrics.py:276] Avg prompt throughput: 139.9 tokens/s, Avg generation throughput: 4.6 tokens/s, Running: 22 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%
INFO:     ::1:40242 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:31 api_server.py:155] waiting for model...
INFO 05-12 10:38:31 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40288 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:31 async_llm_engine.py:437] Reloading model to delta-2
INFO 05-12 10:38:36 api_server.py:155] waiting for model...
INFO 05-12 10:38:36 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:36 metrics.py:276] Avg prompt throughput: 3.3 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO:     ::1:40290 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:36 async_llm_engine.py:437] Reloading model to delta-5
INFO 05-12 10:38:41 api_server.py:155] waiting for model...
INFO 05-12 10:38:41 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO:     ::1:40122 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:41 async_llm_engine.py:437] Reloading model to delta-8
INFO 05-12 10:38:46 api_server.py:155] waiting for model...
INFO 05-12 10:38:46 api_server.py:163] requested model is loaded --> continuing...
Prefetching is disabled
INFO 05-12 10:38:46 metrics.py:276] Avg prompt throughput: 3.3 tokens/s, Avg generation throughput: 15.5 tokens/s, Running: 21 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO:     ::1:40332 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40146 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40310 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40302 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40306 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40320 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40308 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:51 metrics.py:276] Avg prompt throughput: 8.4 tokens/s, Avg generation throughput: 462.3 tokens/s, Running: 15 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO:     ::1:40248 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40336 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40328 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40312 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40246 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40298 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40214 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40300 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40270 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40220 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:38:56 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 248.2 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%
INFO:     ::1:40316 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40314 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 05-12 10:39:01 metrics.py:276] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 102.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO:     ::1:40330 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40280 - "POST /v1/completions HTTP/1.1" 200 OK
INFO:     ::1:40322 - "POST /v1/completions HTTP/1.1" 200 OK
Results written to .artifact/benchmarks/results/a151a410-e865-4062-b7b7-21492b4509a5.jsonl
Killing process 111013...
/var/spool/slurmd/job3671402/slurm_script: line 42: 110979 Killed                  apptainer run --nv --home /mnt/petrelfs/huqinghao/xzyao/:/home/xiayao --bind /mnt/petrelfs/huqinghao/xzyao/code/vllm:/vllm --bind /mnt/petrelfs/huqinghao/xzyao/code/triteia:/triteia --env PYTHONPATH=/vllm:/triteia --env CUDA_LAUNCH_BLOCKING=1 --env TVM_TARGET=nvidia/nvidia-a100 --env BITBLAS_TARGET=nvidia/nvidia-a100 --env RAY_DEDUP_LOGS=0 --workdir /vllm /mnt/petrelfs/huqinghao/xzyao/images/deltaserve.sif python3 /vllm/vllm/entrypoints/openai/api_server.py --model /vllm/.idea/full_models/Llama-2-13b-hf --disable-log-requests --gpu-memory-utilization 0.85 --swap-modules delta-1=/vllm/.idea/full_models/Llama-2-13b-hf-1 delta-2=/vllm/.idea/full_models/Llama-2-13b-hf-2 delta-3=/vllm/.idea/full_models/Llama-2-13b-hf-3 delta-4=/vllm/.idea/full_models/Llama-2-13b-hf-4 delta-5=/vllm/.idea/full_models/Llama-2-13b-hf-5 delta-6=/vllm/.idea/full_models/Llama-2-13b-hf-6 delta-7=/vllm/.idea/full_models/Llama-2-13b-hf-7 delta-8=/vllm/.idea/full_models/Llama-2-13b-hf-8 --tensor-parallel-size 4 --enforce-eager --max-deltas 0
